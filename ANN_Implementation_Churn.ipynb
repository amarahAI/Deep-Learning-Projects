{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN_Implementation_Churn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NS0skJ71HaaE"
      },
      "outputs": [],
      "source": [
        "# connected GPU #CONNECT IT"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ANN"
      ],
      "metadata": {
        "id": "UD6uwGteHhij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67SfnFYIIHw2",
        "outputId": "ed65913e-019b-426c-bdd2-55b371f6ab92"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-gpu\n",
            "  Downloading tensorflow_gpu-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 511.7 MB 6.3 kB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (4.1.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.14.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.21.6)\n",
            "Collecting flatbuffers<2,>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (21.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.47.0)\n",
            "Collecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (14.0.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.26.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.17.3)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 62.3 MB/s \n",
            "\u001b[?25hCollecting tensorboard<2.10,>=2.9\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 47.7 MB/s \n",
            "\u001b[?25hCollecting keras<2.10.0,>=2.9.0rc0\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 55.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (57.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow-gpu) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (0.6.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-gpu) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow-gpu) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow-gpu) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-gpu) (3.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-gpu) (3.0.9)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, gast, flatbuffers, tensorflow-gpu\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.2+zzzcolab20220527125636 requires keras<2.9,>=2.8.0rc0, but you have keras 2.9.0 which is incompatible.\n",
            "tensorflow 2.8.2+zzzcolab20220527125636 requires tensorboard<2.9,>=2.8, but you have tensorboard 2.9.1 which is incompatible.\n",
            "tensorflow 2.8.2+zzzcolab20220527125636 requires tensorflow-estimator<2.9,>=2.8, but you have tensorflow-estimator 2.9.0 which is incompatible.\u001b[0m\n",
            "Successfully installed flatbuffers-1.12 gast-0.4.0 keras-2.9.0 tensorboard-2.9.1 tensorflow-estimator-2.9.0 tensorflow-gpu-2.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vl work with version greater than 2.0 so we get the keras integrated with it."
      ],
      "metadata": {
        "id": "qhKSB0zeIOFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)#it has keras integrated"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3wXIMbxIcKA",
        "outputId": "e0547f30-1fca-4b24-eb7e-bdcaa9c3e5af"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Coi9sMFaI6Jd",
        "outputId": "cd7d6497-bbb3-4711-d975-96b73dd97b92"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import some basic libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "nrXdhZzrIiLH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=pd.read_csv(\"Churn_Modelling.csv\")"
      ],
      "metadata": {
        "id": "fWcz0hybIxOT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "-H4iMI4VI47G",
        "outputId": "9e45d3f4-1f45-4dfd-bf46-33daa3c57685"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
              "0          1    15634602  Hargrave          619    France  Female   42   \n",
              "1          2    15647311      Hill          608     Spain  Female   41   \n",
              "2          3    15619304      Onio          502    France  Female   42   \n",
              "3          4    15701354      Boni          699    France  Female   39   \n",
              "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
              "\n",
              "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
              "0       2       0.00              1          1               1   \n",
              "1       1   83807.86              1          0               1   \n",
              "2       8  159660.80              3          1               0   \n",
              "3       1       0.00              2          0               0   \n",
              "4       2  125510.82              1          1               1   \n",
              "\n",
              "   EstimatedSalary  Exited  \n",
              "0        101348.88       1  \n",
              "1        112542.58       0  \n",
              "2        113931.57       1  \n",
              "3         93826.63       0  \n",
              "4         79084.10       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-54069c41-d521-43c0-9237-7e990360ba11\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54069c41-d521-43c0-9237-7e990360ba11')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-54069c41-d521-43c0-9237-7e990360ba11 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-54069c41-d521-43c0-9237-7e990360ba11');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uBSDs4dJ1D_",
        "outputId": "c629a7c4-c942-40d9-adcc-328b3f1b8cc3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography',\n",
              "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
              "       'IsActiveMember', 'EstimatedSalary', 'Exited'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# binary classification model - cust vl exit or not. If u want to prevent then provide some services. so vl create model to see if cust vl leave or not"
      ],
      "metadata": {
        "id": "TP0x_qj1JLtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# divide the dataset into independent & dependent features"
      ],
      "metadata": {
        "id": "fqtcez8ZJc-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vl remove rowno, name - not needed"
      ],
      "metadata": {
        "id": "g0tMLkW4J-X_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=dataset.iloc[:,3:13]\n",
        "y=dataset.iloc[:,13]"
      ],
      "metadata": {
        "id": "9ZJO4dJ7JrKv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "kcLlPjDaKSy4",
        "outputId": "9dfb5d58-736c-4d99-ea89-d895ab9b2366"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
              "0          619    France  Female   42       2       0.00              1   \n",
              "1          608     Spain  Female   41       1   83807.86              1   \n",
              "2          502    France  Female   42       8  159660.80              3   \n",
              "3          699    France  Female   39       1       0.00              2   \n",
              "4          850     Spain  Female   43       2  125510.82              1   \n",
              "\n",
              "   HasCrCard  IsActiveMember  EstimatedSalary  \n",
              "0          1               1        101348.88  \n",
              "1          0               1        112542.58  \n",
              "2          1               0        113931.57  \n",
              "3          0               0         93826.63  \n",
              "4          1               1         79084.10  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-74a044c2-3f53-4cac-a5c3-2cf473f67f93\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74a044c2-3f53-4cac-a5c3-2cf473f67f93')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-74a044c2-3f53-4cac-a5c3-2cf473f67f93 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-74a044c2-3f53-4cac-a5c3-2cf473f67f93');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykxqvnmNKVCD",
        "outputId": "2a2d2ac4-fb70-4966-e50c-660c10523ec7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       1\n",
              "1       0\n",
              "2       1\n",
              "3       0\n",
              "4       0\n",
              "       ..\n",
              "9995    0\n",
              "9996    0\n",
              "9997    1\n",
              "9998    1\n",
              "9999    0\n",
              "Name: Exited, Length: 10000, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we have categorical features.. need to fix this. less category so one hot we can use"
      ],
      "metadata": {
        "id": "_E_WpqOeKadL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# so lets start with Feature engineering"
      ],
      "metadata": {
        "id": "S-I1zjRRKlTw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "z71IOKfRLAYg",
        "outputId": "8435511d-2477-4b8f-e93d-abf4c79fdd9a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   CreditScore Geography  Gender  Age  Tenure   Balance  NumOfProducts  \\\n",
              "0          619    France  Female   42       2      0.00              1   \n",
              "1          608     Spain  Female   41       1  83807.86              1   \n",
              "\n",
              "   HasCrCard  IsActiveMember  EstimatedSalary  \n",
              "0          1               1        101348.88  \n",
              "1          0               1        112542.58  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-192a7ccc-1152-4806-944e-e352cc6789c3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-192a7ccc-1152-4806-944e-e352cc6789c3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-192a7ccc-1152-4806-944e-e352cc6789c3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-192a7ccc-1152-4806-944e-e352cc6789c3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['Geography'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhcJ-3vHLZZm",
        "outputId": "102f7dc5-97cd-4e88-f129-7a8db6a29600"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "France     5014\n",
              "Germany    2509\n",
              "Spain      2477\n",
              "Name: Geography, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.get_dummies(X['Geography'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "4CzPAsYmLAiZ",
        "outputId": "609868aa-d57b-401b-d989-efe4fa7614c4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      France  Germany  Spain\n",
              "0          1        0      0\n",
              "1          0        0      1\n",
              "2          1        0      0\n",
              "3          1        0      0\n",
              "4          0        0      1\n",
              "...      ...      ...    ...\n",
              "9995       1        0      0\n",
              "9996       1        0      0\n",
              "9997       1        0      0\n",
              "9998       0        1      0\n",
              "9999       1        0      0\n",
              "\n",
              "[10000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c9e86bb0-5899-4f80-8a05-89992ca9f4e0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>France</th>\n",
              "      <th>Germany</th>\n",
              "      <th>Spain</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c9e86bb0-5899-4f80-8a05-89992ca9f4e0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c9e86bb0-5899-4f80-8a05-89992ca9f4e0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c9e86bb0-5899-4f80-8a05-89992ca9f4e0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.get_dummies(X['Geography'],drop_first=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "IJr6E_yyLf0W",
        "outputId": "9bb0e883-8831-45d1-a952-5366ac2c09f7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Germany  Spain\n",
              "0           0      0\n",
              "1           0      1\n",
              "2           0      0\n",
              "3           0      0\n",
              "4           0      1\n",
              "...       ...    ...\n",
              "9995        0      0\n",
              "9996        0      0\n",
              "9997        0      0\n",
              "9998        1      0\n",
              "9999        0      0\n",
              "\n",
              "[10000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1705cebf-89ea-4f46-894f-863ad2538ae3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Germany</th>\n",
              "      <th>Spain</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1705cebf-89ea-4f46-894f-863ad2538ae3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1705cebf-89ea-4f46-894f-863ad2538ae3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1705cebf-89ea-4f46-894f-863ad2538ae3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "geography=pd.get_dummies(X['Geography'],drop_first=True)\n",
        "gender=pd.get_dummies(X['Gender'],drop_first=True)"
      ],
      "metadata": {
        "id": "dfy8uVa4Lr6j"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.drop(['Geography','Gender'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "UiX7_z3MNlUm"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "6HwbANfMN2SX",
        "outputId": "706a6fb5-abba-45cc-de95-acdceff90c89"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   CreditScore  Age  Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
              "0          619   42       2      0.00              1          1   \n",
              "1          608   41       1  83807.86              1          0   \n",
              "\n",
              "   IsActiveMember  EstimatedSalary  \n",
              "0               1        101348.88  \n",
              "1               1        112542.58  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f0863f88-da7f-43b4-ac45-b745c264909d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0863f88-da7f-43b4-ac45-b745c264909d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f0863f88-da7f-43b4-ac45-b745c264909d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f0863f88-da7f-43b4-ac45-b745c264909d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# concat these variable with dataframe"
      ],
      "metadata": {
        "id": "juUYnZEVNesH"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([X,geography,gender], axis=1) #column wise so write axis=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "Q12LI93wN30n",
        "outputId": "2fb38d2a-f715-49a6-dfb4-960ceed7bd0a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
              "0             619   42       2       0.00              1          1   \n",
              "1             608   41       1   83807.86              1          0   \n",
              "2             502   42       8  159660.80              3          1   \n",
              "3             699   39       1       0.00              2          0   \n",
              "4             850   43       2  125510.82              1          1   \n",
              "...           ...  ...     ...        ...            ...        ...   \n",
              "9995          771   39       5       0.00              2          1   \n",
              "9996          516   35      10   57369.61              1          1   \n",
              "9997          709   36       7       0.00              1          0   \n",
              "9998          772   42       3   75075.31              2          1   \n",
              "9999          792   28       4  130142.79              1          1   \n",
              "\n",
              "      IsActiveMember  EstimatedSalary  Germany  Spain  Male  \n",
              "0                  1        101348.88        0      0     0  \n",
              "1                  1        112542.58        0      1     0  \n",
              "2                  0        113931.57        0      0     0  \n",
              "3                  0         93826.63        0      0     0  \n",
              "4                  1         79084.10        0      1     0  \n",
              "...              ...              ...      ...    ...   ...  \n",
              "9995               0         96270.64        0      0     1  \n",
              "9996               1        101699.77        0      0     1  \n",
              "9997               1         42085.58        0      0     0  \n",
              "9998               0         92888.52        1      0     1  \n",
              "9999               0         38190.78        0      0     0  \n",
              "\n",
              "[10000 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e0f277ec-8974-413c-b362-2e88a90116ea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Germany</th>\n",
              "      <th>Spain</th>\n",
              "      <th>Male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>771</td>\n",
              "      <td>39</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>96270.64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>516</td>\n",
              "      <td>35</td>\n",
              "      <td>10</td>\n",
              "      <td>57369.61</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101699.77</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>709</td>\n",
              "      <td>36</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>42085.58</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>772</td>\n",
              "      <td>42</td>\n",
              "      <td>3</td>\n",
              "      <td>75075.31</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>92888.52</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>792</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>130142.79</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38190.78</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e0f277ec-8974-413c-b362-2e88a90116ea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e0f277ec-8974-413c-b362-2e88a90116ea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e0f277ec-8974-413c-b362-2e88a90116ea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=pd.concat([X,geography,gender], axis=1) #column wise so write axis=1"
      ],
      "metadata": {
        "id": "8uoGE3ueOF5f"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting the dataset into training & test set\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "CzcmnDgwOiZ_"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
      ],
      "metadata": {
        "id": "Garx7ncSOqQb"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ANN - Feature scaling"
      ],
      "metadata": {
        "id": "_-sa0Yt5O04H"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#feature scaling\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler # based on z score is stand scaler\n",
        "\n",
        "sc=StandardScaler()\n",
        "X_train=sc.fit_transform(X_train) \n",
        "\n",
        "X_test=sc.transform(X_test) \n",
        "\n"
      ],
      "metadata": {
        "id": "q-WUh9v-D1gR"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rZvjgN9Eu6o",
        "outputId": "1df6165f-80ed-4579-8757-5e166edf0fb8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.16958176, -0.46460796,  0.00666099, ..., -0.5698444 ,\n",
              "         1.74309049, -1.09168714],\n",
              "       [-2.30455945,  0.30102557, -1.37744033, ...,  1.75486502,\n",
              "        -0.57369368,  0.91601335],\n",
              "       [-1.19119591, -0.94312892, -1.031415  , ..., -0.5698444 ,\n",
              "        -0.57369368, -1.09168714],\n",
              "       ...,\n",
              "       [ 0.9015152 , -0.36890377,  0.00666099, ..., -0.5698444 ,\n",
              "        -0.57369368,  0.91601335],\n",
              "       [-0.62420521, -0.08179119,  1.39076231, ..., -0.5698444 ,\n",
              "         1.74309049, -1.09168714],\n",
              "       [-0.28401079,  0.87525072, -1.37744033, ...,  1.75486502,\n",
              "        -0.57369368, -1.09168714]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V--Ai2TOE4IB",
        "outputId": "5e321e21-eede-4fc7-b7e5-38f485fcedd5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.55204276, -0.36890377,  1.04473698, ...,  1.75486502,\n",
              "        -0.57369368, -1.09168714],\n",
              "       [-1.31490297,  0.10961719, -1.031415  , ..., -0.5698444 ,\n",
              "        -0.57369368, -1.09168714],\n",
              "       [ 0.57162971,  0.30102557,  1.04473698, ..., -0.5698444 ,\n",
              "         1.74309049, -1.09168714],\n",
              "       ...,\n",
              "       [-0.74791227, -0.27319958, -1.37744033, ..., -0.5698444 ,\n",
              "         1.74309049,  0.91601335],\n",
              "       [-0.00566991, -0.46460796, -0.33936434, ...,  1.75486502,\n",
              "        -0.57369368,  0.91601335],\n",
              "       [-0.79945688, -0.84742473,  1.04473698, ...,  1.75486502,\n",
              "        -0.57369368,  0.91601335]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62n20Z3YE7B3",
        "outputId": "47aa962c-767a-4337-ad53-d3b5b76093f4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SB3b0nwsE-eJ",
        "outputId": "159d35e0-e7bb-4e97-836b-6282c6b35b99"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fit transform is used only in training dataset - to avoid data leakage"
      ],
      "metadata": {
        "id": "roA_qp_-FAwL"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Part 2 - ANN"
      ],
      "metadata": {
        "id": "5Ll5CSqoFJv8"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANN"
      ],
      "metadata": {
        "id": "qSvfa_3SGWGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Tensorflow  - google\n",
        "# pytorch - facebook\n",
        "# keras used tensorflow -before.\n",
        "#keras is inside tensforflow  - now\n",
        "\n"
      ],
      "metadata": {
        "id": "6xE5o3gPFJ_K"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential #all neural n/w at once\n",
        "\n",
        "from tensorflow.keras.layers import Dense #for I/p, hidden layers and o/p layers\n",
        "\n",
        "from tensorflow.keras.layers import LeakyReLU,PReLU,ELU,ReLU #activation function used in HL\n",
        "\n",
        "from tensorflow.keras.layers import Dropout #to reduce overfitting"
      ],
      "metadata": {
        "id": "ZikucJ66Guij"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets initialize the ANN\n",
        "\n",
        "classifier=Sequential()\n",
        "\n"
      ],
      "metadata": {
        "id": "dk4Lz0dfHJyU"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding the input layer - x_train - 11 col\n",
        "\n",
        "classifier.add(Dense(units=11,activation='relu')) #11 features/col are there in dataset\n",
        "# and relu will get applied to the next upcoming layer.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FZVj2qw3KSy3"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding the first hidden layer\n",
        "\n",
        "classifier.add(Dense(units=7,activation='relu')) #lets take 7, whatever you want"
      ],
      "metadata": {
        "id": "kyLenmF9Kg-1"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding the second hidden layer\n",
        "\n",
        "classifier.add(Dense(units=6,activation='relu'))"
      ],
      "metadata": {
        "id": "n0tsi646Ko8h"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding the output layer\n",
        "\n",
        "classifier.add(Dense(1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "JmR8uyyHKtvr"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "2ZSRiTIbK5UU"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adam uses by default learning rate of 0.01"
      ],
      "metadata": {
        "id": "nMh2yVCmLJmY"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if u want to decide ur own learning rate use below with whatever value we want\n",
        "\n",
        "import tensorflow\n",
        "tensorflow.keras.optimizers.Adam(learning_rate=0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGz5wLLALP9k",
        "outputId": "0946f0db-d16d-413a-8fd8-e8d84482b31b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.optimizers.optimizer_v2.adam.Adam at 0x7f22ef4ec090>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_history=classifier.fit(X_train,y_train,validation_split=0.33,batch_size=10,epochs=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSr72K0YLcDu",
        "outputId": "593338d4-f7e9-4afb-b72b-a3c95b46b008"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "536/536 [==============================] - 4s 4ms/step - loss: 0.4817 - accuracy: 0.8037 - val_loss: 0.4358 - val_accuracy: 0.8137\n",
            "Epoch 2/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.4195 - accuracy: 0.8257 - val_loss: 0.4133 - val_accuracy: 0.8239\n",
            "Epoch 3/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.4063 - accuracy: 0.8302 - val_loss: 0.4081 - val_accuracy: 0.8213\n",
            "Epoch 4/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3972 - accuracy: 0.8345 - val_loss: 0.4024 - val_accuracy: 0.8277\n",
            "Epoch 5/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3909 - accuracy: 0.8339 - val_loss: 0.3966 - val_accuracy: 0.8258\n",
            "Epoch 6/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3841 - accuracy: 0.8341 - val_loss: 0.3890 - val_accuracy: 0.8258\n",
            "Epoch 7/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3762 - accuracy: 0.8362 - val_loss: 0.3810 - val_accuracy: 0.8307\n",
            "Epoch 8/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3695 - accuracy: 0.8343 - val_loss: 0.3760 - val_accuracy: 0.8315\n",
            "Epoch 9/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3639 - accuracy: 0.8468 - val_loss: 0.3707 - val_accuracy: 0.8448\n",
            "Epoch 10/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3583 - accuracy: 0.8513 - val_loss: 0.3750 - val_accuracy: 0.8387\n",
            "Epoch 11/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3548 - accuracy: 0.8520 - val_loss: 0.3695 - val_accuracy: 0.8463\n",
            "Epoch 12/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3509 - accuracy: 0.8524 - val_loss: 0.3634 - val_accuracy: 0.8516\n",
            "Epoch 13/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3477 - accuracy: 0.8578 - val_loss: 0.3634 - val_accuracy: 0.8554\n",
            "Epoch 14/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3461 - accuracy: 0.8606 - val_loss: 0.3608 - val_accuracy: 0.8531\n",
            "Epoch 15/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3439 - accuracy: 0.8604 - val_loss: 0.3626 - val_accuracy: 0.8557\n",
            "Epoch 16/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3407 - accuracy: 0.8617 - val_loss: 0.3593 - val_accuracy: 0.8527\n",
            "Epoch 17/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3397 - accuracy: 0.8630 - val_loss: 0.3660 - val_accuracy: 0.8531\n",
            "Epoch 18/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3379 - accuracy: 0.8617 - val_loss: 0.3611 - val_accuracy: 0.8538\n",
            "Epoch 19/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3369 - accuracy: 0.8653 - val_loss: 0.3587 - val_accuracy: 0.8573\n",
            "Epoch 20/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3360 - accuracy: 0.8632 - val_loss: 0.3561 - val_accuracy: 0.8588\n",
            "Epoch 21/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3351 - accuracy: 0.8632 - val_loss: 0.3552 - val_accuracy: 0.8599\n",
            "Epoch 22/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3348 - accuracy: 0.8627 - val_loss: 0.3557 - val_accuracy: 0.8610\n",
            "Epoch 23/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3323 - accuracy: 0.8656 - val_loss: 0.3536 - val_accuracy: 0.8637\n",
            "Epoch 24/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3316 - accuracy: 0.8643 - val_loss: 0.3572 - val_accuracy: 0.8573\n",
            "Epoch 25/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3308 - accuracy: 0.8660 - val_loss: 0.3538 - val_accuracy: 0.8565\n",
            "Epoch 26/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3302 - accuracy: 0.8656 - val_loss: 0.3558 - val_accuracy: 0.8554\n",
            "Epoch 27/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3292 - accuracy: 0.8668 - val_loss: 0.3563 - val_accuracy: 0.8561\n",
            "Epoch 28/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3301 - accuracy: 0.8638 - val_loss: 0.3542 - val_accuracy: 0.8576\n",
            "Epoch 29/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3265 - accuracy: 0.8643 - val_loss: 0.3532 - val_accuracy: 0.8580\n",
            "Epoch 30/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3289 - accuracy: 0.8668 - val_loss: 0.3539 - val_accuracy: 0.8561\n",
            "Epoch 31/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3268 - accuracy: 0.8651 - val_loss: 0.3556 - val_accuracy: 0.8576\n",
            "Epoch 32/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3282 - accuracy: 0.8649 - val_loss: 0.3617 - val_accuracy: 0.8485\n",
            "Epoch 33/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3264 - accuracy: 0.8668 - val_loss: 0.3533 - val_accuracy: 0.8588\n",
            "Epoch 34/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3263 - accuracy: 0.8675 - val_loss: 0.3522 - val_accuracy: 0.8565\n",
            "Epoch 35/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3260 - accuracy: 0.8670 - val_loss: 0.3540 - val_accuracy: 0.8584\n",
            "Epoch 36/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3245 - accuracy: 0.8638 - val_loss: 0.3601 - val_accuracy: 0.8474\n",
            "Epoch 37/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3240 - accuracy: 0.8675 - val_loss: 0.3528 - val_accuracy: 0.8591\n",
            "Epoch 38/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3245 - accuracy: 0.8653 - val_loss: 0.3526 - val_accuracy: 0.8595\n",
            "Epoch 39/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3253 - accuracy: 0.8645 - val_loss: 0.3601 - val_accuracy: 0.8512\n",
            "Epoch 40/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3249 - accuracy: 0.8660 - val_loss: 0.3525 - val_accuracy: 0.8554\n",
            "Epoch 41/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3234 - accuracy: 0.8662 - val_loss: 0.3557 - val_accuracy: 0.8546\n",
            "Epoch 42/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3228 - accuracy: 0.8666 - val_loss: 0.3558 - val_accuracy: 0.8523\n",
            "Epoch 43/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3236 - accuracy: 0.8670 - val_loss: 0.3571 - val_accuracy: 0.8535\n",
            "Epoch 44/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3236 - accuracy: 0.8692 - val_loss: 0.3532 - val_accuracy: 0.8550\n",
            "Epoch 45/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3228 - accuracy: 0.8671 - val_loss: 0.3556 - val_accuracy: 0.8588\n",
            "Epoch 46/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3231 - accuracy: 0.8651 - val_loss: 0.3548 - val_accuracy: 0.8554\n",
            "Epoch 47/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3221 - accuracy: 0.8690 - val_loss: 0.3551 - val_accuracy: 0.8542\n",
            "Epoch 48/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3218 - accuracy: 0.8671 - val_loss: 0.3577 - val_accuracy: 0.8523\n",
            "Epoch 49/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3226 - accuracy: 0.8662 - val_loss: 0.3581 - val_accuracy: 0.8538\n",
            "Epoch 50/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3221 - accuracy: 0.8656 - val_loss: 0.3561 - val_accuracy: 0.8535\n",
            "Epoch 51/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3217 - accuracy: 0.8671 - val_loss: 0.3583 - val_accuracy: 0.8493\n",
            "Epoch 52/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3212 - accuracy: 0.8681 - val_loss: 0.3583 - val_accuracy: 0.8516\n",
            "Epoch 53/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3215 - accuracy: 0.8671 - val_loss: 0.3593 - val_accuracy: 0.8485\n",
            "Epoch 54/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3221 - accuracy: 0.8660 - val_loss: 0.3543 - val_accuracy: 0.8535\n",
            "Epoch 55/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3196 - accuracy: 0.8703 - val_loss: 0.3620 - val_accuracy: 0.8463\n",
            "Epoch 56/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3202 - accuracy: 0.8673 - val_loss: 0.3593 - val_accuracy: 0.8542\n",
            "Epoch 57/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3210 - accuracy: 0.8671 - val_loss: 0.3534 - val_accuracy: 0.8561\n",
            "Epoch 58/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3197 - accuracy: 0.8703 - val_loss: 0.3596 - val_accuracy: 0.8504\n",
            "Epoch 59/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3209 - accuracy: 0.8688 - val_loss: 0.3544 - val_accuracy: 0.8573\n",
            "Epoch 60/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3193 - accuracy: 0.8712 - val_loss: 0.3564 - val_accuracy: 0.8550\n",
            "Epoch 61/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3214 - accuracy: 0.8677 - val_loss: 0.3567 - val_accuracy: 0.8538\n",
            "Epoch 62/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3198 - accuracy: 0.8656 - val_loss: 0.3582 - val_accuracy: 0.8489\n",
            "Epoch 63/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3195 - accuracy: 0.8664 - val_loss: 0.3583 - val_accuracy: 0.8501\n",
            "Epoch 64/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3195 - accuracy: 0.8670 - val_loss: 0.3595 - val_accuracy: 0.8444\n",
            "Epoch 65/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3187 - accuracy: 0.8671 - val_loss: 0.3576 - val_accuracy: 0.8523\n",
            "Epoch 66/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3188 - accuracy: 0.8679 - val_loss: 0.3546 - val_accuracy: 0.8535\n",
            "Epoch 67/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3180 - accuracy: 0.8671 - val_loss: 0.3583 - val_accuracy: 0.8561\n",
            "Epoch 68/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3173 - accuracy: 0.8707 - val_loss: 0.3579 - val_accuracy: 0.8493\n",
            "Epoch 69/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3179 - accuracy: 0.8705 - val_loss: 0.3632 - val_accuracy: 0.8470\n",
            "Epoch 70/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3176 - accuracy: 0.8683 - val_loss: 0.3563 - val_accuracy: 0.8531\n",
            "Epoch 71/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3180 - accuracy: 0.8670 - val_loss: 0.3543 - val_accuracy: 0.8550\n",
            "Epoch 72/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3180 - accuracy: 0.8699 - val_loss: 0.3593 - val_accuracy: 0.8485\n",
            "Epoch 73/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3156 - accuracy: 0.8683 - val_loss: 0.3549 - val_accuracy: 0.8546\n",
            "Epoch 74/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3172 - accuracy: 0.8699 - val_loss: 0.3568 - val_accuracy: 0.8478\n",
            "Epoch 75/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3170 - accuracy: 0.8690 - val_loss: 0.3563 - val_accuracy: 0.8512\n",
            "Epoch 76/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3178 - accuracy: 0.8649 - val_loss: 0.3641 - val_accuracy: 0.8444\n",
            "Epoch 77/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3172 - accuracy: 0.8675 - val_loss: 0.3552 - val_accuracy: 0.8561\n",
            "Epoch 78/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3171 - accuracy: 0.8703 - val_loss: 0.3588 - val_accuracy: 0.8501\n",
            "Epoch 79/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3163 - accuracy: 0.8705 - val_loss: 0.3553 - val_accuracy: 0.8542\n",
            "Epoch 80/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3170 - accuracy: 0.8670 - val_loss: 0.3589 - val_accuracy: 0.8466\n",
            "Epoch 81/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3163 - accuracy: 0.8683 - val_loss: 0.3604 - val_accuracy: 0.8493\n",
            "Epoch 82/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3158 - accuracy: 0.8675 - val_loss: 0.3573 - val_accuracy: 0.8550\n",
            "Epoch 83/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3160 - accuracy: 0.8698 - val_loss: 0.3518 - val_accuracy: 0.8546\n",
            "Epoch 84/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3151 - accuracy: 0.8692 - val_loss: 0.3539 - val_accuracy: 0.8557\n",
            "Epoch 85/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3149 - accuracy: 0.8692 - val_loss: 0.3556 - val_accuracy: 0.8527\n",
            "Epoch 86/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3157 - accuracy: 0.8692 - val_loss: 0.3512 - val_accuracy: 0.8584\n",
            "Epoch 87/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3151 - accuracy: 0.8709 - val_loss: 0.3548 - val_accuracy: 0.8576\n",
            "Epoch 88/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3140 - accuracy: 0.8696 - val_loss: 0.3568 - val_accuracy: 0.8531\n",
            "Epoch 89/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3147 - accuracy: 0.8701 - val_loss: 0.3549 - val_accuracy: 0.8546\n",
            "Epoch 90/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3148 - accuracy: 0.8666 - val_loss: 0.3585 - val_accuracy: 0.8478\n",
            "Epoch 91/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3141 - accuracy: 0.8711 - val_loss: 0.3563 - val_accuracy: 0.8519\n",
            "Epoch 92/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3132 - accuracy: 0.8711 - val_loss: 0.3530 - val_accuracy: 0.8535\n",
            "Epoch 93/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3142 - accuracy: 0.8686 - val_loss: 0.3528 - val_accuracy: 0.8599\n",
            "Epoch 94/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3125 - accuracy: 0.8696 - val_loss: 0.3568 - val_accuracy: 0.8554\n",
            "Epoch 95/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3147 - accuracy: 0.8701 - val_loss: 0.3529 - val_accuracy: 0.8576\n",
            "Epoch 96/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3139 - accuracy: 0.8670 - val_loss: 0.3560 - val_accuracy: 0.8554\n",
            "Epoch 97/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3122 - accuracy: 0.8683 - val_loss: 0.3541 - val_accuracy: 0.8595\n",
            "Epoch 98/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3142 - accuracy: 0.8701 - val_loss: 0.3599 - val_accuracy: 0.8512\n",
            "Epoch 99/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3131 - accuracy: 0.8701 - val_loss: 0.3532 - val_accuracy: 0.8538\n",
            "Epoch 100/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3134 - accuracy: 0.8699 - val_loss: 0.3589 - val_accuracy: 0.8501\n",
            "Epoch 101/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3129 - accuracy: 0.8692 - val_loss: 0.3556 - val_accuracy: 0.8542\n",
            "Epoch 102/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3116 - accuracy: 0.8724 - val_loss: 0.3576 - val_accuracy: 0.8561\n",
            "Epoch 103/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3126 - accuracy: 0.8703 - val_loss: 0.3590 - val_accuracy: 0.8493\n",
            "Epoch 104/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3123 - accuracy: 0.8709 - val_loss: 0.3602 - val_accuracy: 0.8512\n",
            "Epoch 105/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3130 - accuracy: 0.8673 - val_loss: 0.3583 - val_accuracy: 0.8478\n",
            "Epoch 106/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3127 - accuracy: 0.8701 - val_loss: 0.3577 - val_accuracy: 0.8535\n",
            "Epoch 107/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3130 - accuracy: 0.8716 - val_loss: 0.3547 - val_accuracy: 0.8531\n",
            "Epoch 108/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3119 - accuracy: 0.8705 - val_loss: 0.3528 - val_accuracy: 0.8588\n",
            "Epoch 109/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3127 - accuracy: 0.8698 - val_loss: 0.3560 - val_accuracy: 0.8584\n",
            "Epoch 110/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3113 - accuracy: 0.8707 - val_loss: 0.3609 - val_accuracy: 0.8523\n",
            "Epoch 111/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3114 - accuracy: 0.8686 - val_loss: 0.3557 - val_accuracy: 0.8576\n",
            "Epoch 112/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3108 - accuracy: 0.8698 - val_loss: 0.3550 - val_accuracy: 0.8516\n",
            "Epoch 113/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3109 - accuracy: 0.8714 - val_loss: 0.3538 - val_accuracy: 0.8573\n",
            "Epoch 114/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3110 - accuracy: 0.8731 - val_loss: 0.3524 - val_accuracy: 0.8565\n",
            "Epoch 115/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3109 - accuracy: 0.8701 - val_loss: 0.3544 - val_accuracy: 0.8580\n",
            "Epoch 116/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3116 - accuracy: 0.8753 - val_loss: 0.3527 - val_accuracy: 0.8580\n",
            "Epoch 117/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3115 - accuracy: 0.8726 - val_loss: 0.3539 - val_accuracy: 0.8569\n",
            "Epoch 118/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3109 - accuracy: 0.8726 - val_loss: 0.3536 - val_accuracy: 0.8569\n",
            "Epoch 119/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3113 - accuracy: 0.8714 - val_loss: 0.3548 - val_accuracy: 0.8554\n",
            "Epoch 120/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3104 - accuracy: 0.8735 - val_loss: 0.3564 - val_accuracy: 0.8512\n",
            "Epoch 121/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3109 - accuracy: 0.8737 - val_loss: 0.3571 - val_accuracy: 0.8531\n",
            "Epoch 122/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3109 - accuracy: 0.8698 - val_loss: 0.3554 - val_accuracy: 0.8523\n",
            "Epoch 123/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3106 - accuracy: 0.8739 - val_loss: 0.3570 - val_accuracy: 0.8561\n",
            "Epoch 124/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3105 - accuracy: 0.8718 - val_loss: 0.3589 - val_accuracy: 0.8501\n",
            "Epoch 125/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3101 - accuracy: 0.8726 - val_loss: 0.3591 - val_accuracy: 0.8512\n",
            "Epoch 126/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3107 - accuracy: 0.8712 - val_loss: 0.3534 - val_accuracy: 0.8569\n",
            "Epoch 127/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3109 - accuracy: 0.8737 - val_loss: 0.3532 - val_accuracy: 0.8573\n",
            "Epoch 128/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3103 - accuracy: 0.8739 - val_loss: 0.3520 - val_accuracy: 0.8595\n",
            "Epoch 129/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3092 - accuracy: 0.8729 - val_loss: 0.3519 - val_accuracy: 0.8554\n",
            "Epoch 130/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3093 - accuracy: 0.8727 - val_loss: 0.3543 - val_accuracy: 0.8554\n",
            "Epoch 131/1000\n",
            "536/536 [==============================] - 4s 7ms/step - loss: 0.3093 - accuracy: 0.8727 - val_loss: 0.3567 - val_accuracy: 0.8554\n",
            "Epoch 132/1000\n",
            "536/536 [==============================] - 4s 7ms/step - loss: 0.3105 - accuracy: 0.8709 - val_loss: 0.3564 - val_accuracy: 0.8531\n",
            "Epoch 133/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3090 - accuracy: 0.8737 - val_loss: 0.3563 - val_accuracy: 0.8531\n",
            "Epoch 134/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3095 - accuracy: 0.8729 - val_loss: 0.3525 - val_accuracy: 0.8542\n",
            "Epoch 135/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3092 - accuracy: 0.8703 - val_loss: 0.3567 - val_accuracy: 0.8489\n",
            "Epoch 136/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3096 - accuracy: 0.8716 - val_loss: 0.3553 - val_accuracy: 0.8527\n",
            "Epoch 137/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3083 - accuracy: 0.8755 - val_loss: 0.3556 - val_accuracy: 0.8569\n",
            "Epoch 138/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3094 - accuracy: 0.8712 - val_loss: 0.3553 - val_accuracy: 0.8576\n",
            "Epoch 139/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3079 - accuracy: 0.8735 - val_loss: 0.3554 - val_accuracy: 0.8584\n",
            "Epoch 140/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3083 - accuracy: 0.8712 - val_loss: 0.3545 - val_accuracy: 0.8519\n",
            "Epoch 141/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3085 - accuracy: 0.8739 - val_loss: 0.3567 - val_accuracy: 0.8527\n",
            "Epoch 142/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3081 - accuracy: 0.8737 - val_loss: 0.3554 - val_accuracy: 0.8561\n",
            "Epoch 143/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3079 - accuracy: 0.8733 - val_loss: 0.3572 - val_accuracy: 0.8516\n",
            "Epoch 144/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3073 - accuracy: 0.8727 - val_loss: 0.3622 - val_accuracy: 0.8482\n",
            "Epoch 145/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3082 - accuracy: 0.8731 - val_loss: 0.3535 - val_accuracy: 0.8565\n",
            "Epoch 146/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3071 - accuracy: 0.8727 - val_loss: 0.3632 - val_accuracy: 0.8485\n",
            "Epoch 147/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3067 - accuracy: 0.8737 - val_loss: 0.3584 - val_accuracy: 0.8561\n",
            "Epoch 148/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3090 - accuracy: 0.8711 - val_loss: 0.3566 - val_accuracy: 0.8554\n",
            "Epoch 149/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3073 - accuracy: 0.8761 - val_loss: 0.3563 - val_accuracy: 0.8523\n",
            "Epoch 150/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3074 - accuracy: 0.8722 - val_loss: 0.3567 - val_accuracy: 0.8561\n",
            "Epoch 151/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3077 - accuracy: 0.8742 - val_loss: 0.3593 - val_accuracy: 0.8538\n",
            "Epoch 152/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3069 - accuracy: 0.8748 - val_loss: 0.3570 - val_accuracy: 0.8557\n",
            "Epoch 153/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3072 - accuracy: 0.8746 - val_loss: 0.3555 - val_accuracy: 0.8516\n",
            "Epoch 154/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3065 - accuracy: 0.8727 - val_loss: 0.3574 - val_accuracy: 0.8580\n",
            "Epoch 155/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3063 - accuracy: 0.8727 - val_loss: 0.3557 - val_accuracy: 0.8561\n",
            "Epoch 156/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3070 - accuracy: 0.8742 - val_loss: 0.3576 - val_accuracy: 0.8554\n",
            "Epoch 157/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3067 - accuracy: 0.8722 - val_loss: 0.3568 - val_accuracy: 0.8569\n",
            "Epoch 158/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3059 - accuracy: 0.8770 - val_loss: 0.3558 - val_accuracy: 0.8561\n",
            "Epoch 159/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3070 - accuracy: 0.8770 - val_loss: 0.3549 - val_accuracy: 0.8554\n",
            "Epoch 160/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3069 - accuracy: 0.8729 - val_loss: 0.3643 - val_accuracy: 0.8508\n",
            "Epoch 161/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3064 - accuracy: 0.8709 - val_loss: 0.3573 - val_accuracy: 0.8527\n",
            "Epoch 162/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3071 - accuracy: 0.8731 - val_loss: 0.3550 - val_accuracy: 0.8573\n",
            "Epoch 163/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3073 - accuracy: 0.8740 - val_loss: 0.3584 - val_accuracy: 0.8531\n",
            "Epoch 164/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3068 - accuracy: 0.8742 - val_loss: 0.3587 - val_accuracy: 0.8504\n",
            "Epoch 165/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3063 - accuracy: 0.8735 - val_loss: 0.3567 - val_accuracy: 0.8561\n",
            "Epoch 166/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3057 - accuracy: 0.8750 - val_loss: 0.3571 - val_accuracy: 0.8557\n",
            "Epoch 167/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3058 - accuracy: 0.8752 - val_loss: 0.3559 - val_accuracy: 0.8576\n",
            "Epoch 168/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3055 - accuracy: 0.8746 - val_loss: 0.3555 - val_accuracy: 0.8538\n",
            "Epoch 169/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3060 - accuracy: 0.8740 - val_loss: 0.3574 - val_accuracy: 0.8554\n",
            "Epoch 170/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3054 - accuracy: 0.8752 - val_loss: 0.3628 - val_accuracy: 0.8516\n",
            "Epoch 171/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3048 - accuracy: 0.8785 - val_loss: 0.3560 - val_accuracy: 0.8576\n",
            "Epoch 172/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3050 - accuracy: 0.8755 - val_loss: 0.3576 - val_accuracy: 0.8561\n",
            "Epoch 173/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3055 - accuracy: 0.8753 - val_loss: 0.3539 - val_accuracy: 0.8580\n",
            "Epoch 174/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3061 - accuracy: 0.8720 - val_loss: 0.3594 - val_accuracy: 0.8512\n",
            "Epoch 175/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3061 - accuracy: 0.8742 - val_loss: 0.3646 - val_accuracy: 0.8497\n",
            "Epoch 176/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3055 - accuracy: 0.8753 - val_loss: 0.3531 - val_accuracy: 0.8565\n",
            "Epoch 177/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3044 - accuracy: 0.8759 - val_loss: 0.3558 - val_accuracy: 0.8576\n",
            "Epoch 178/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3042 - accuracy: 0.8753 - val_loss: 0.3612 - val_accuracy: 0.8569\n",
            "Epoch 179/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3053 - accuracy: 0.8750 - val_loss: 0.3564 - val_accuracy: 0.8535\n",
            "Epoch 180/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3048 - accuracy: 0.8753 - val_loss: 0.3575 - val_accuracy: 0.8546\n",
            "Epoch 181/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3063 - accuracy: 0.8722 - val_loss: 0.3591 - val_accuracy: 0.8523\n",
            "Epoch 182/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3050 - accuracy: 0.8740 - val_loss: 0.3575 - val_accuracy: 0.8535\n",
            "Epoch 183/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3048 - accuracy: 0.8778 - val_loss: 0.3547 - val_accuracy: 0.8633\n",
            "Epoch 184/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3042 - accuracy: 0.8744 - val_loss: 0.3575 - val_accuracy: 0.8573\n",
            "Epoch 185/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3044 - accuracy: 0.8753 - val_loss: 0.3601 - val_accuracy: 0.8542\n",
            "Epoch 186/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3047 - accuracy: 0.8752 - val_loss: 0.3535 - val_accuracy: 0.8591\n",
            "Epoch 187/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3031 - accuracy: 0.8739 - val_loss: 0.3591 - val_accuracy: 0.8561\n",
            "Epoch 188/1000\n",
            "536/536 [==============================] - 3s 6ms/step - loss: 0.3046 - accuracy: 0.8727 - val_loss: 0.3554 - val_accuracy: 0.8599\n",
            "Epoch 189/1000\n",
            "536/536 [==============================] - 4s 8ms/step - loss: 0.3047 - accuracy: 0.8740 - val_loss: 0.3583 - val_accuracy: 0.8569\n",
            "Epoch 190/1000\n",
            "536/536 [==============================] - 4s 8ms/step - loss: 0.3042 - accuracy: 0.8733 - val_loss: 0.3558 - val_accuracy: 0.8565\n",
            "Epoch 191/1000\n",
            "536/536 [==============================] - 4s 7ms/step - loss: 0.3041 - accuracy: 0.8733 - val_loss: 0.3609 - val_accuracy: 0.8535\n",
            "Epoch 192/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3037 - accuracy: 0.8753 - val_loss: 0.3568 - val_accuracy: 0.8591\n",
            "Epoch 193/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3036 - accuracy: 0.8729 - val_loss: 0.3595 - val_accuracy: 0.8523\n",
            "Epoch 194/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3048 - accuracy: 0.8763 - val_loss: 0.3568 - val_accuracy: 0.8607\n",
            "Epoch 195/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3038 - accuracy: 0.8740 - val_loss: 0.3593 - val_accuracy: 0.8550\n",
            "Epoch 196/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3037 - accuracy: 0.8755 - val_loss: 0.3620 - val_accuracy: 0.8527\n",
            "Epoch 197/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3038 - accuracy: 0.8720 - val_loss: 0.3625 - val_accuracy: 0.8531\n",
            "Epoch 198/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3030 - accuracy: 0.8739 - val_loss: 0.3584 - val_accuracy: 0.8550\n",
            "Epoch 199/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3014 - accuracy: 0.8755 - val_loss: 0.3640 - val_accuracy: 0.8561\n",
            "Epoch 200/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3042 - accuracy: 0.8714 - val_loss: 0.3577 - val_accuracy: 0.8573\n",
            "Epoch 201/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3026 - accuracy: 0.8755 - val_loss: 0.3570 - val_accuracy: 0.8610\n",
            "Epoch 202/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3030 - accuracy: 0.8746 - val_loss: 0.3589 - val_accuracy: 0.8561\n",
            "Epoch 203/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3027 - accuracy: 0.8778 - val_loss: 0.3649 - val_accuracy: 0.8538\n",
            "Epoch 204/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3033 - accuracy: 0.8750 - val_loss: 0.3592 - val_accuracy: 0.8554\n",
            "Epoch 205/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3018 - accuracy: 0.8739 - val_loss: 0.3607 - val_accuracy: 0.8546\n",
            "Epoch 206/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3020 - accuracy: 0.8750 - val_loss: 0.3593 - val_accuracy: 0.8546\n",
            "Epoch 207/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3023 - accuracy: 0.8765 - val_loss: 0.3772 - val_accuracy: 0.8448\n",
            "Epoch 208/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3032 - accuracy: 0.8737 - val_loss: 0.3591 - val_accuracy: 0.8538\n",
            "Epoch 209/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3024 - accuracy: 0.8763 - val_loss: 0.3655 - val_accuracy: 0.8504\n",
            "Epoch 210/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3032 - accuracy: 0.8726 - val_loss: 0.3572 - val_accuracy: 0.8535\n",
            "Epoch 211/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3018 - accuracy: 0.8737 - val_loss: 0.3581 - val_accuracy: 0.8588\n",
            "Epoch 212/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3027 - accuracy: 0.8735 - val_loss: 0.3579 - val_accuracy: 0.8599\n",
            "Epoch 213/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3014 - accuracy: 0.8763 - val_loss: 0.3654 - val_accuracy: 0.8512\n",
            "Epoch 214/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3031 - accuracy: 0.8763 - val_loss: 0.3587 - val_accuracy: 0.8569\n",
            "Epoch 215/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3018 - accuracy: 0.8722 - val_loss: 0.3597 - val_accuracy: 0.8542\n",
            "Epoch 216/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3025 - accuracy: 0.8761 - val_loss: 0.3616 - val_accuracy: 0.8588\n",
            "Epoch 217/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3005 - accuracy: 0.8740 - val_loss: 0.3665 - val_accuracy: 0.8501\n",
            "Epoch 218/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.3001 - accuracy: 0.8742 - val_loss: 0.3683 - val_accuracy: 0.8516\n",
            "Epoch 219/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.3017 - accuracy: 0.8731 - val_loss: 0.3652 - val_accuracy: 0.8535\n",
            "Epoch 220/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3023 - accuracy: 0.8720 - val_loss: 0.3620 - val_accuracy: 0.8531\n",
            "Epoch 221/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3008 - accuracy: 0.8765 - val_loss: 0.3628 - val_accuracy: 0.8538\n",
            "Epoch 222/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3019 - accuracy: 0.8765 - val_loss: 0.3646 - val_accuracy: 0.8516\n",
            "Epoch 223/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3014 - accuracy: 0.8748 - val_loss: 0.3624 - val_accuracy: 0.8557\n",
            "Epoch 224/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3004 - accuracy: 0.8746 - val_loss: 0.3650 - val_accuracy: 0.8535\n",
            "Epoch 225/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3010 - accuracy: 0.8765 - val_loss: 0.3626 - val_accuracy: 0.8550\n",
            "Epoch 226/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3015 - accuracy: 0.8752 - val_loss: 0.3620 - val_accuracy: 0.8557\n",
            "Epoch 227/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3005 - accuracy: 0.8742 - val_loss: 0.3635 - val_accuracy: 0.8554\n",
            "Epoch 228/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3002 - accuracy: 0.8778 - val_loss: 0.3638 - val_accuracy: 0.8573\n",
            "Epoch 229/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2992 - accuracy: 0.8739 - val_loss: 0.3654 - val_accuracy: 0.8550\n",
            "Epoch 230/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3003 - accuracy: 0.8757 - val_loss: 0.3628 - val_accuracy: 0.8550\n",
            "Epoch 231/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2997 - accuracy: 0.8726 - val_loss: 0.3605 - val_accuracy: 0.8584\n",
            "Epoch 232/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3001 - accuracy: 0.8767 - val_loss: 0.3700 - val_accuracy: 0.8516\n",
            "Epoch 233/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3001 - accuracy: 0.8739 - val_loss: 0.3654 - val_accuracy: 0.8557\n",
            "Epoch 234/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3022 - accuracy: 0.8729 - val_loss: 0.3664 - val_accuracy: 0.8497\n",
            "Epoch 235/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2999 - accuracy: 0.8750 - val_loss: 0.3643 - val_accuracy: 0.8550\n",
            "Epoch 236/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3011 - accuracy: 0.8753 - val_loss: 0.3623 - val_accuracy: 0.8573\n",
            "Epoch 237/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2988 - accuracy: 0.8737 - val_loss: 0.3700 - val_accuracy: 0.8527\n",
            "Epoch 238/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2989 - accuracy: 0.8757 - val_loss: 0.3690 - val_accuracy: 0.8535\n",
            "Epoch 239/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2997 - accuracy: 0.8750 - val_loss: 0.3635 - val_accuracy: 0.8554\n",
            "Epoch 240/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3002 - accuracy: 0.8755 - val_loss: 0.3627 - val_accuracy: 0.8542\n",
            "Epoch 241/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2986 - accuracy: 0.8768 - val_loss: 0.3638 - val_accuracy: 0.8565\n",
            "Epoch 242/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2987 - accuracy: 0.8753 - val_loss: 0.3713 - val_accuracy: 0.8508\n",
            "Epoch 243/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2989 - accuracy: 0.8744 - val_loss: 0.3685 - val_accuracy: 0.8531\n",
            "Epoch 244/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2983 - accuracy: 0.8768 - val_loss: 0.3655 - val_accuracy: 0.8546\n",
            "Epoch 245/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2988 - accuracy: 0.8776 - val_loss: 0.3639 - val_accuracy: 0.8542\n",
            "Epoch 246/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2992 - accuracy: 0.8735 - val_loss: 0.3654 - val_accuracy: 0.8531\n",
            "Epoch 247/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2996 - accuracy: 0.8759 - val_loss: 0.3642 - val_accuracy: 0.8557\n",
            "Epoch 248/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2987 - accuracy: 0.8755 - val_loss: 0.3617 - val_accuracy: 0.8546\n",
            "Epoch 249/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2984 - accuracy: 0.8776 - val_loss: 0.3834 - val_accuracy: 0.8421\n",
            "Epoch 250/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2987 - accuracy: 0.8726 - val_loss: 0.3689 - val_accuracy: 0.8535\n",
            "Epoch 251/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2981 - accuracy: 0.8755 - val_loss: 0.3624 - val_accuracy: 0.8531\n",
            "Epoch 252/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2980 - accuracy: 0.8759 - val_loss: 0.3681 - val_accuracy: 0.8527\n",
            "Epoch 253/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2983 - accuracy: 0.8748 - val_loss: 0.3670 - val_accuracy: 0.8519\n",
            "Epoch 254/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2996 - accuracy: 0.8755 - val_loss: 0.3696 - val_accuracy: 0.8519\n",
            "Epoch 255/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2978 - accuracy: 0.8753 - val_loss: 0.3642 - val_accuracy: 0.8561\n",
            "Epoch 256/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2977 - accuracy: 0.8759 - val_loss: 0.3665 - val_accuracy: 0.8550\n",
            "Epoch 257/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2986 - accuracy: 0.8746 - val_loss: 0.3637 - val_accuracy: 0.8550\n",
            "Epoch 258/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2981 - accuracy: 0.8755 - val_loss: 0.3674 - val_accuracy: 0.8535\n",
            "Epoch 259/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2985 - accuracy: 0.8755 - val_loss: 0.3613 - val_accuracy: 0.8565\n",
            "Epoch 260/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2979 - accuracy: 0.8772 - val_loss: 0.3675 - val_accuracy: 0.8550\n",
            "Epoch 261/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2969 - accuracy: 0.8793 - val_loss: 0.3792 - val_accuracy: 0.8470\n",
            "Epoch 262/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2987 - accuracy: 0.8763 - val_loss: 0.3676 - val_accuracy: 0.8523\n",
            "Epoch 263/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2979 - accuracy: 0.8767 - val_loss: 0.3666 - val_accuracy: 0.8512\n",
            "Epoch 264/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2962 - accuracy: 0.8753 - val_loss: 0.3687 - val_accuracy: 0.8497\n",
            "Epoch 265/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2970 - accuracy: 0.8780 - val_loss: 0.3832 - val_accuracy: 0.8478\n",
            "Epoch 266/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2969 - accuracy: 0.8750 - val_loss: 0.3744 - val_accuracy: 0.8497\n",
            "Epoch 267/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2985 - accuracy: 0.8744 - val_loss: 0.3668 - val_accuracy: 0.8519\n",
            "Epoch 268/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2971 - accuracy: 0.8780 - val_loss: 0.3723 - val_accuracy: 0.8501\n",
            "Epoch 269/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2968 - accuracy: 0.8759 - val_loss: 0.3676 - val_accuracy: 0.8512\n",
            "Epoch 270/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2962 - accuracy: 0.8804 - val_loss: 0.3732 - val_accuracy: 0.8512\n",
            "Epoch 271/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2962 - accuracy: 0.8739 - val_loss: 0.3795 - val_accuracy: 0.8459\n",
            "Epoch 272/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2985 - accuracy: 0.8783 - val_loss: 0.3723 - val_accuracy: 0.8512\n",
            "Epoch 273/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2982 - accuracy: 0.8748 - val_loss: 0.3695 - val_accuracy: 0.8523\n",
            "Epoch 274/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2969 - accuracy: 0.8795 - val_loss: 0.3658 - val_accuracy: 0.8565\n",
            "Epoch 275/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2959 - accuracy: 0.8780 - val_loss: 0.3671 - val_accuracy: 0.8519\n",
            "Epoch 276/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2967 - accuracy: 0.8742 - val_loss: 0.3699 - val_accuracy: 0.8519\n",
            "Epoch 277/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2970 - accuracy: 0.8763 - val_loss: 0.3717 - val_accuracy: 0.8527\n",
            "Epoch 278/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2974 - accuracy: 0.8781 - val_loss: 0.3702 - val_accuracy: 0.8527\n",
            "Epoch 279/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2969 - accuracy: 0.8778 - val_loss: 0.3719 - val_accuracy: 0.8508\n",
            "Epoch 280/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2967 - accuracy: 0.8791 - val_loss: 0.3722 - val_accuracy: 0.8535\n",
            "Epoch 281/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2965 - accuracy: 0.8765 - val_loss: 0.3679 - val_accuracy: 0.8519\n",
            "Epoch 282/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2976 - accuracy: 0.8759 - val_loss: 0.3686 - val_accuracy: 0.8527\n",
            "Epoch 283/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2953 - accuracy: 0.8763 - val_loss: 0.3687 - val_accuracy: 0.8531\n",
            "Epoch 284/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2979 - accuracy: 0.8767 - val_loss: 0.3677 - val_accuracy: 0.8508\n",
            "Epoch 285/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2962 - accuracy: 0.8763 - val_loss: 0.3738 - val_accuracy: 0.8508\n",
            "Epoch 286/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2965 - accuracy: 0.8770 - val_loss: 0.3740 - val_accuracy: 0.8493\n",
            "Epoch 287/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2960 - accuracy: 0.8783 - val_loss: 0.3718 - val_accuracy: 0.8516\n",
            "Epoch 288/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2959 - accuracy: 0.8798 - val_loss: 0.3762 - val_accuracy: 0.8489\n",
            "Epoch 289/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2949 - accuracy: 0.8765 - val_loss: 0.3701 - val_accuracy: 0.8531\n",
            "Epoch 290/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2964 - accuracy: 0.8781 - val_loss: 0.3739 - val_accuracy: 0.8489\n",
            "Epoch 291/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2953 - accuracy: 0.8767 - val_loss: 0.3726 - val_accuracy: 0.8478\n",
            "Epoch 292/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2972 - accuracy: 0.8776 - val_loss: 0.3752 - val_accuracy: 0.8470\n",
            "Epoch 293/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2963 - accuracy: 0.8761 - val_loss: 0.3763 - val_accuracy: 0.8463\n",
            "Epoch 294/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2966 - accuracy: 0.8746 - val_loss: 0.3769 - val_accuracy: 0.8466\n",
            "Epoch 295/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2959 - accuracy: 0.8772 - val_loss: 0.3766 - val_accuracy: 0.8493\n",
            "Epoch 296/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2945 - accuracy: 0.8767 - val_loss: 0.3673 - val_accuracy: 0.8550\n",
            "Epoch 297/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2943 - accuracy: 0.8757 - val_loss: 0.3718 - val_accuracy: 0.8519\n",
            "Epoch 298/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2959 - accuracy: 0.8765 - val_loss: 0.3728 - val_accuracy: 0.8531\n",
            "Epoch 299/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2953 - accuracy: 0.8772 - val_loss: 0.3703 - val_accuracy: 0.8531\n",
            "Epoch 300/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2954 - accuracy: 0.8796 - val_loss: 0.3727 - val_accuracy: 0.8546\n",
            "Epoch 301/1000\n",
            "536/536 [==============================] - 4s 7ms/step - loss: 0.2950 - accuracy: 0.8776 - val_loss: 0.3738 - val_accuracy: 0.8519\n",
            "Epoch 302/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.2945 - accuracy: 0.8761 - val_loss: 0.3739 - val_accuracy: 0.8523\n",
            "Epoch 303/1000\n",
            "536/536 [==============================] - 4s 8ms/step - loss: 0.2947 - accuracy: 0.8780 - val_loss: 0.3745 - val_accuracy: 0.8561\n",
            "Epoch 304/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2948 - accuracy: 0.8765 - val_loss: 0.3747 - val_accuracy: 0.8497\n",
            "Epoch 305/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2933 - accuracy: 0.8796 - val_loss: 0.3831 - val_accuracy: 0.8501\n",
            "Epoch 306/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2948 - accuracy: 0.8808 - val_loss: 0.3734 - val_accuracy: 0.8519\n",
            "Epoch 307/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2957 - accuracy: 0.8785 - val_loss: 0.3797 - val_accuracy: 0.8466\n",
            "Epoch 308/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2930 - accuracy: 0.8804 - val_loss: 0.3709 - val_accuracy: 0.8519\n",
            "Epoch 309/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2949 - accuracy: 0.8776 - val_loss: 0.3683 - val_accuracy: 0.8531\n",
            "Epoch 310/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2939 - accuracy: 0.8774 - val_loss: 0.3747 - val_accuracy: 0.8523\n",
            "Epoch 311/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2944 - accuracy: 0.8796 - val_loss: 0.3726 - val_accuracy: 0.8546\n",
            "Epoch 312/1000\n",
            "536/536 [==============================] - 4s 7ms/step - loss: 0.2930 - accuracy: 0.8778 - val_loss: 0.3740 - val_accuracy: 0.8523\n",
            "Epoch 313/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2933 - accuracy: 0.8800 - val_loss: 0.3783 - val_accuracy: 0.8470\n",
            "Epoch 314/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2941 - accuracy: 0.8770 - val_loss: 0.3710 - val_accuracy: 0.8569\n",
            "Epoch 315/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2934 - accuracy: 0.8783 - val_loss: 0.3704 - val_accuracy: 0.8523\n",
            "Epoch 316/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2940 - accuracy: 0.8781 - val_loss: 0.3716 - val_accuracy: 0.8565\n",
            "Epoch 317/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2925 - accuracy: 0.8767 - val_loss: 0.3735 - val_accuracy: 0.8455\n",
            "Epoch 318/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2948 - accuracy: 0.8780 - val_loss: 0.3715 - val_accuracy: 0.8489\n",
            "Epoch 319/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2941 - accuracy: 0.8778 - val_loss: 0.3742 - val_accuracy: 0.8538\n",
            "Epoch 320/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2936 - accuracy: 0.8761 - val_loss: 0.3711 - val_accuracy: 0.8546\n",
            "Epoch 321/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2944 - accuracy: 0.8761 - val_loss: 0.3738 - val_accuracy: 0.8519\n",
            "Epoch 322/1000\n",
            "536/536 [==============================] - 4s 7ms/step - loss: 0.2928 - accuracy: 0.8776 - val_loss: 0.3728 - val_accuracy: 0.8482\n",
            "Epoch 323/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2928 - accuracy: 0.8798 - val_loss: 0.3836 - val_accuracy: 0.8425\n",
            "Epoch 324/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2929 - accuracy: 0.8800 - val_loss: 0.3737 - val_accuracy: 0.8519\n",
            "Epoch 325/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2930 - accuracy: 0.8791 - val_loss: 0.3782 - val_accuracy: 0.8557\n",
            "Epoch 326/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2935 - accuracy: 0.8787 - val_loss: 0.3721 - val_accuracy: 0.8519\n",
            "Epoch 327/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2939 - accuracy: 0.8780 - val_loss: 0.3741 - val_accuracy: 0.8531\n",
            "Epoch 328/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2939 - accuracy: 0.8767 - val_loss: 0.3764 - val_accuracy: 0.8508\n",
            "Epoch 329/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2928 - accuracy: 0.8798 - val_loss: 0.3773 - val_accuracy: 0.8501\n",
            "Epoch 330/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2931 - accuracy: 0.8763 - val_loss: 0.3733 - val_accuracy: 0.8538\n",
            "Epoch 331/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2929 - accuracy: 0.8804 - val_loss: 0.3770 - val_accuracy: 0.8527\n",
            "Epoch 332/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2931 - accuracy: 0.8785 - val_loss: 0.3763 - val_accuracy: 0.8554\n",
            "Epoch 333/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2937 - accuracy: 0.8793 - val_loss: 0.3742 - val_accuracy: 0.8527\n",
            "Epoch 334/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2920 - accuracy: 0.8798 - val_loss: 0.3835 - val_accuracy: 0.8478\n",
            "Epoch 335/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2937 - accuracy: 0.8767 - val_loss: 0.3765 - val_accuracy: 0.8512\n",
            "Epoch 336/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2931 - accuracy: 0.8780 - val_loss: 0.3755 - val_accuracy: 0.8538\n",
            "Epoch 337/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2924 - accuracy: 0.8787 - val_loss: 0.3828 - val_accuracy: 0.8508\n",
            "Epoch 338/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2933 - accuracy: 0.8776 - val_loss: 0.3776 - val_accuracy: 0.8493\n",
            "Epoch 339/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2921 - accuracy: 0.8793 - val_loss: 0.3782 - val_accuracy: 0.8493\n",
            "Epoch 340/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2922 - accuracy: 0.8761 - val_loss: 0.3729 - val_accuracy: 0.8546\n",
            "Epoch 341/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2920 - accuracy: 0.8791 - val_loss: 0.3742 - val_accuracy: 0.8535\n",
            "Epoch 342/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2913 - accuracy: 0.8800 - val_loss: 0.3747 - val_accuracy: 0.8516\n",
            "Epoch 343/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2914 - accuracy: 0.8787 - val_loss: 0.3818 - val_accuracy: 0.8466\n",
            "Epoch 344/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2928 - accuracy: 0.8804 - val_loss: 0.3764 - val_accuracy: 0.8565\n",
            "Epoch 345/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2929 - accuracy: 0.8774 - val_loss: 0.3809 - val_accuracy: 0.8493\n",
            "Epoch 346/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2910 - accuracy: 0.8800 - val_loss: 0.3759 - val_accuracy: 0.8497\n",
            "Epoch 347/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2906 - accuracy: 0.8781 - val_loss: 0.3824 - val_accuracy: 0.8440\n",
            "Epoch 348/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2925 - accuracy: 0.8774 - val_loss: 0.3797 - val_accuracy: 0.8474\n",
            "Epoch 349/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2912 - accuracy: 0.8765 - val_loss: 0.3741 - val_accuracy: 0.8538\n",
            "Epoch 350/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2915 - accuracy: 0.8778 - val_loss: 0.3815 - val_accuracy: 0.8508\n",
            "Epoch 351/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2901 - accuracy: 0.8772 - val_loss: 0.3773 - val_accuracy: 0.8580\n",
            "Epoch 352/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2915 - accuracy: 0.8783 - val_loss: 0.3788 - val_accuracy: 0.8474\n",
            "Epoch 353/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2918 - accuracy: 0.8770 - val_loss: 0.3769 - val_accuracy: 0.8527\n",
            "Epoch 354/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2922 - accuracy: 0.8781 - val_loss: 0.3760 - val_accuracy: 0.8523\n",
            "Epoch 355/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2912 - accuracy: 0.8796 - val_loss: 0.3839 - val_accuracy: 0.8489\n",
            "Epoch 356/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2924 - accuracy: 0.8780 - val_loss: 0.3774 - val_accuracy: 0.8523\n",
            "Epoch 357/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2914 - accuracy: 0.8780 - val_loss: 0.3769 - val_accuracy: 0.8527\n",
            "Epoch 358/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2902 - accuracy: 0.8793 - val_loss: 0.3908 - val_accuracy: 0.8387\n",
            "Epoch 359/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2921 - accuracy: 0.8795 - val_loss: 0.3782 - val_accuracy: 0.8523\n",
            "Epoch 360/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2907 - accuracy: 0.8800 - val_loss: 0.3746 - val_accuracy: 0.8516\n",
            "Epoch 361/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2902 - accuracy: 0.8793 - val_loss: 0.3840 - val_accuracy: 0.8501\n",
            "Epoch 362/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2913 - accuracy: 0.8761 - val_loss: 0.3820 - val_accuracy: 0.8516\n",
            "Epoch 363/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2910 - accuracy: 0.8787 - val_loss: 0.3759 - val_accuracy: 0.8485\n",
            "Epoch 364/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2906 - accuracy: 0.8763 - val_loss: 0.3756 - val_accuracy: 0.8542\n",
            "Epoch 365/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2915 - accuracy: 0.8768 - val_loss: 0.3748 - val_accuracy: 0.8512\n",
            "Epoch 366/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2908 - accuracy: 0.8791 - val_loss: 0.3799 - val_accuracy: 0.8504\n",
            "Epoch 367/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2917 - accuracy: 0.8789 - val_loss: 0.3783 - val_accuracy: 0.8485\n",
            "Epoch 368/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2908 - accuracy: 0.8793 - val_loss: 0.3808 - val_accuracy: 0.8516\n",
            "Epoch 369/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2903 - accuracy: 0.8778 - val_loss: 0.3778 - val_accuracy: 0.8546\n",
            "Epoch 370/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2911 - accuracy: 0.8811 - val_loss: 0.3794 - val_accuracy: 0.8516\n",
            "Epoch 371/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2898 - accuracy: 0.8785 - val_loss: 0.3777 - val_accuracy: 0.8546\n",
            "Epoch 372/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2913 - accuracy: 0.8770 - val_loss: 0.3807 - val_accuracy: 0.8519\n",
            "Epoch 373/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2918 - accuracy: 0.8785 - val_loss: 0.3777 - val_accuracy: 0.8508\n",
            "Epoch 374/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2902 - accuracy: 0.8791 - val_loss: 0.3791 - val_accuracy: 0.8523\n",
            "Epoch 375/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2920 - accuracy: 0.8796 - val_loss: 0.3807 - val_accuracy: 0.8519\n",
            "Epoch 376/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2902 - accuracy: 0.8776 - val_loss: 0.3816 - val_accuracy: 0.8519\n",
            "Epoch 377/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2912 - accuracy: 0.8802 - val_loss: 0.3794 - val_accuracy: 0.8508\n",
            "Epoch 378/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2897 - accuracy: 0.8798 - val_loss: 0.3826 - val_accuracy: 0.8489\n",
            "Epoch 379/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2904 - accuracy: 0.8802 - val_loss: 0.3771 - val_accuracy: 0.8508\n",
            "Epoch 380/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2895 - accuracy: 0.8819 - val_loss: 0.3804 - val_accuracy: 0.8482\n",
            "Epoch 381/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2909 - accuracy: 0.8793 - val_loss: 0.3859 - val_accuracy: 0.8451\n",
            "Epoch 382/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2906 - accuracy: 0.8789 - val_loss: 0.3765 - val_accuracy: 0.8512\n",
            "Epoch 383/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2901 - accuracy: 0.8806 - val_loss: 0.3772 - val_accuracy: 0.8546\n",
            "Epoch 384/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2892 - accuracy: 0.8806 - val_loss: 0.3789 - val_accuracy: 0.8527\n",
            "Epoch 385/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2900 - accuracy: 0.8795 - val_loss: 0.3835 - val_accuracy: 0.8504\n",
            "Epoch 386/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2897 - accuracy: 0.8789 - val_loss: 0.3850 - val_accuracy: 0.8429\n",
            "Epoch 387/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2890 - accuracy: 0.8778 - val_loss: 0.3791 - val_accuracy: 0.8497\n",
            "Epoch 388/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2889 - accuracy: 0.8809 - val_loss: 0.3842 - val_accuracy: 0.8527\n",
            "Epoch 389/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2891 - accuracy: 0.8815 - val_loss: 0.3733 - val_accuracy: 0.8501\n",
            "Epoch 390/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2896 - accuracy: 0.8787 - val_loss: 0.3783 - val_accuracy: 0.8504\n",
            "Epoch 391/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2904 - accuracy: 0.8781 - val_loss: 0.3787 - val_accuracy: 0.8531\n",
            "Epoch 392/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2886 - accuracy: 0.8808 - val_loss: 0.3823 - val_accuracy: 0.8466\n",
            "Epoch 393/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2891 - accuracy: 0.8823 - val_loss: 0.3758 - val_accuracy: 0.8527\n",
            "Epoch 394/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2891 - accuracy: 0.8806 - val_loss: 0.3785 - val_accuracy: 0.8466\n",
            "Epoch 395/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2901 - accuracy: 0.8783 - val_loss: 0.3806 - val_accuracy: 0.8489\n",
            "Epoch 396/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2893 - accuracy: 0.8811 - val_loss: 0.3782 - val_accuracy: 0.8516\n",
            "Epoch 397/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2895 - accuracy: 0.8808 - val_loss: 0.3853 - val_accuracy: 0.8440\n",
            "Epoch 398/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2895 - accuracy: 0.8813 - val_loss: 0.3804 - val_accuracy: 0.8444\n",
            "Epoch 399/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2891 - accuracy: 0.8823 - val_loss: 0.3797 - val_accuracy: 0.8512\n",
            "Epoch 400/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2883 - accuracy: 0.8808 - val_loss: 0.3821 - val_accuracy: 0.8501\n",
            "Epoch 401/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2903 - accuracy: 0.8774 - val_loss: 0.3783 - val_accuracy: 0.8523\n",
            "Epoch 402/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2905 - accuracy: 0.8791 - val_loss: 0.3824 - val_accuracy: 0.8440\n",
            "Epoch 403/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2887 - accuracy: 0.8811 - val_loss: 0.3836 - val_accuracy: 0.8482\n",
            "Epoch 404/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2898 - accuracy: 0.8757 - val_loss: 0.3832 - val_accuracy: 0.8550\n",
            "Epoch 405/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2893 - accuracy: 0.8781 - val_loss: 0.3780 - val_accuracy: 0.8523\n",
            "Epoch 406/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2896 - accuracy: 0.8768 - val_loss: 0.3842 - val_accuracy: 0.8436\n",
            "Epoch 407/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2905 - accuracy: 0.8774 - val_loss: 0.3758 - val_accuracy: 0.8504\n",
            "Epoch 408/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2891 - accuracy: 0.8776 - val_loss: 0.3776 - val_accuracy: 0.8489\n",
            "Epoch 409/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2885 - accuracy: 0.8778 - val_loss: 0.3903 - val_accuracy: 0.8398\n",
            "Epoch 410/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2890 - accuracy: 0.8767 - val_loss: 0.3770 - val_accuracy: 0.8493\n",
            "Epoch 411/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2893 - accuracy: 0.8787 - val_loss: 0.3784 - val_accuracy: 0.8489\n",
            "Epoch 412/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2897 - accuracy: 0.8809 - val_loss: 0.3803 - val_accuracy: 0.8512\n",
            "Epoch 413/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2893 - accuracy: 0.8804 - val_loss: 0.3785 - val_accuracy: 0.8489\n",
            "Epoch 414/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2894 - accuracy: 0.8789 - val_loss: 0.3828 - val_accuracy: 0.8444\n",
            "Epoch 415/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2898 - accuracy: 0.8793 - val_loss: 0.3802 - val_accuracy: 0.8474\n",
            "Epoch 416/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2888 - accuracy: 0.8787 - val_loss: 0.3865 - val_accuracy: 0.8485\n",
            "Epoch 417/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2894 - accuracy: 0.8795 - val_loss: 0.3813 - val_accuracy: 0.8497\n",
            "Epoch 418/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2881 - accuracy: 0.8796 - val_loss: 0.3804 - val_accuracy: 0.8538\n",
            "Epoch 419/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2887 - accuracy: 0.8783 - val_loss: 0.3848 - val_accuracy: 0.8429\n",
            "Epoch 420/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2881 - accuracy: 0.8774 - val_loss: 0.3843 - val_accuracy: 0.8429\n",
            "Epoch 421/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2890 - accuracy: 0.8785 - val_loss: 0.3847 - val_accuracy: 0.8485\n",
            "Epoch 422/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2895 - accuracy: 0.8759 - val_loss: 0.3800 - val_accuracy: 0.8459\n",
            "Epoch 423/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2895 - accuracy: 0.8780 - val_loss: 0.3807 - val_accuracy: 0.8440\n",
            "Epoch 424/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2880 - accuracy: 0.8795 - val_loss: 0.3787 - val_accuracy: 0.8546\n",
            "Epoch 425/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2888 - accuracy: 0.8789 - val_loss: 0.3792 - val_accuracy: 0.8557\n",
            "Epoch 426/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2889 - accuracy: 0.8780 - val_loss: 0.3840 - val_accuracy: 0.8485\n",
            "Epoch 427/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2878 - accuracy: 0.8817 - val_loss: 0.3824 - val_accuracy: 0.8470\n",
            "Epoch 428/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2883 - accuracy: 0.8767 - val_loss: 0.3853 - val_accuracy: 0.8432\n",
            "Epoch 429/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2880 - accuracy: 0.8802 - val_loss: 0.3822 - val_accuracy: 0.8508\n",
            "Epoch 430/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2885 - accuracy: 0.8796 - val_loss: 0.3806 - val_accuracy: 0.8485\n",
            "Epoch 431/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2876 - accuracy: 0.8819 - val_loss: 0.3819 - val_accuracy: 0.8466\n",
            "Epoch 432/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2893 - accuracy: 0.8787 - val_loss: 0.3894 - val_accuracy: 0.8421\n",
            "Epoch 433/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2887 - accuracy: 0.8804 - val_loss: 0.3844 - val_accuracy: 0.8417\n",
            "Epoch 434/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2876 - accuracy: 0.8776 - val_loss: 0.3808 - val_accuracy: 0.8448\n",
            "Epoch 435/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2877 - accuracy: 0.8770 - val_loss: 0.3800 - val_accuracy: 0.8561\n",
            "Epoch 436/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2877 - accuracy: 0.8791 - val_loss: 0.3851 - val_accuracy: 0.8459\n",
            "Epoch 437/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2885 - accuracy: 0.8780 - val_loss: 0.3826 - val_accuracy: 0.8459\n",
            "Epoch 438/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2873 - accuracy: 0.8798 - val_loss: 0.3930 - val_accuracy: 0.8417\n",
            "Epoch 439/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2888 - accuracy: 0.8780 - val_loss: 0.3874 - val_accuracy: 0.8478\n",
            "Epoch 440/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2876 - accuracy: 0.8806 - val_loss: 0.3813 - val_accuracy: 0.8485\n",
            "Epoch 441/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2878 - accuracy: 0.8774 - val_loss: 0.3829 - val_accuracy: 0.8459\n",
            "Epoch 442/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2878 - accuracy: 0.8806 - val_loss: 0.3863 - val_accuracy: 0.8425\n",
            "Epoch 443/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2881 - accuracy: 0.8778 - val_loss: 0.3811 - val_accuracy: 0.8474\n",
            "Epoch 444/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2878 - accuracy: 0.8802 - val_loss: 0.3780 - val_accuracy: 0.8474\n",
            "Epoch 445/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2873 - accuracy: 0.8795 - val_loss: 0.3802 - val_accuracy: 0.8508\n",
            "Epoch 446/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2863 - accuracy: 0.8791 - val_loss: 0.3854 - val_accuracy: 0.8489\n",
            "Epoch 447/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2887 - accuracy: 0.8787 - val_loss: 0.3780 - val_accuracy: 0.8497\n",
            "Epoch 448/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2872 - accuracy: 0.8800 - val_loss: 0.3829 - val_accuracy: 0.8516\n",
            "Epoch 449/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2883 - accuracy: 0.8806 - val_loss: 0.3832 - val_accuracy: 0.8527\n",
            "Epoch 450/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2879 - accuracy: 0.8783 - val_loss: 0.3828 - val_accuracy: 0.8474\n",
            "Epoch 451/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2875 - accuracy: 0.8789 - val_loss: 0.3797 - val_accuracy: 0.8497\n",
            "Epoch 452/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2865 - accuracy: 0.8821 - val_loss: 0.3840 - val_accuracy: 0.8474\n",
            "Epoch 453/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2875 - accuracy: 0.8787 - val_loss: 0.3810 - val_accuracy: 0.8501\n",
            "Epoch 454/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2876 - accuracy: 0.8796 - val_loss: 0.3794 - val_accuracy: 0.8504\n",
            "Epoch 455/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2878 - accuracy: 0.8791 - val_loss: 0.3844 - val_accuracy: 0.8478\n",
            "Epoch 456/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2876 - accuracy: 0.8778 - val_loss: 0.3819 - val_accuracy: 0.8501\n",
            "Epoch 457/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2875 - accuracy: 0.8802 - val_loss: 0.3894 - val_accuracy: 0.8451\n",
            "Epoch 458/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2877 - accuracy: 0.8795 - val_loss: 0.3799 - val_accuracy: 0.8497\n",
            "Epoch 459/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2875 - accuracy: 0.8804 - val_loss: 0.3852 - val_accuracy: 0.8485\n",
            "Epoch 460/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2872 - accuracy: 0.8817 - val_loss: 0.3833 - val_accuracy: 0.8519\n",
            "Epoch 461/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2881 - accuracy: 0.8780 - val_loss: 0.3809 - val_accuracy: 0.8527\n",
            "Epoch 462/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2867 - accuracy: 0.8785 - val_loss: 0.3815 - val_accuracy: 0.8512\n",
            "Epoch 463/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2881 - accuracy: 0.8800 - val_loss: 0.3874 - val_accuracy: 0.8466\n",
            "Epoch 464/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2869 - accuracy: 0.8791 - val_loss: 0.3868 - val_accuracy: 0.8470\n",
            "Epoch 465/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2856 - accuracy: 0.8815 - val_loss: 0.3881 - val_accuracy: 0.8535\n",
            "Epoch 466/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2884 - accuracy: 0.8778 - val_loss: 0.3806 - val_accuracy: 0.8497\n",
            "Epoch 467/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2857 - accuracy: 0.8791 - val_loss: 0.3895 - val_accuracy: 0.8429\n",
            "Epoch 468/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2860 - accuracy: 0.8809 - val_loss: 0.3844 - val_accuracy: 0.8455\n",
            "Epoch 469/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2861 - accuracy: 0.8809 - val_loss: 0.3835 - val_accuracy: 0.8485\n",
            "Epoch 470/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2871 - accuracy: 0.8774 - val_loss: 0.3824 - val_accuracy: 0.8493\n",
            "Epoch 471/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2880 - accuracy: 0.8800 - val_loss: 0.3817 - val_accuracy: 0.8466\n",
            "Epoch 472/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2864 - accuracy: 0.8813 - val_loss: 0.3856 - val_accuracy: 0.8455\n",
            "Epoch 473/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2868 - accuracy: 0.8774 - val_loss: 0.3833 - val_accuracy: 0.8429\n",
            "Epoch 474/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2874 - accuracy: 0.8781 - val_loss: 0.3821 - val_accuracy: 0.8493\n",
            "Epoch 475/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2868 - accuracy: 0.8785 - val_loss: 0.3860 - val_accuracy: 0.8478\n",
            "Epoch 476/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2865 - accuracy: 0.8809 - val_loss: 0.3871 - val_accuracy: 0.8436\n",
            "Epoch 477/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2867 - accuracy: 0.8806 - val_loss: 0.3816 - val_accuracy: 0.8523\n",
            "Epoch 478/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2877 - accuracy: 0.8806 - val_loss: 0.3842 - val_accuracy: 0.8440\n",
            "Epoch 479/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2873 - accuracy: 0.8809 - val_loss: 0.3829 - val_accuracy: 0.8482\n",
            "Epoch 480/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2873 - accuracy: 0.8795 - val_loss: 0.3827 - val_accuracy: 0.8485\n",
            "Epoch 481/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2855 - accuracy: 0.8804 - val_loss: 0.3825 - val_accuracy: 0.8474\n",
            "Epoch 482/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2863 - accuracy: 0.8780 - val_loss: 0.3830 - val_accuracy: 0.8482\n",
            "Epoch 483/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2853 - accuracy: 0.8809 - val_loss: 0.3839 - val_accuracy: 0.8489\n",
            "Epoch 484/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2864 - accuracy: 0.8811 - val_loss: 0.3878 - val_accuracy: 0.8519\n",
            "Epoch 485/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2866 - accuracy: 0.8802 - val_loss: 0.3959 - val_accuracy: 0.8417\n",
            "Epoch 486/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2859 - accuracy: 0.8796 - val_loss: 0.3914 - val_accuracy: 0.8432\n",
            "Epoch 487/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2862 - accuracy: 0.8781 - val_loss: 0.3839 - val_accuracy: 0.8459\n",
            "Epoch 488/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2858 - accuracy: 0.8772 - val_loss: 0.3992 - val_accuracy: 0.8402\n",
            "Epoch 489/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2867 - accuracy: 0.8813 - val_loss: 0.3872 - val_accuracy: 0.8516\n",
            "Epoch 490/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2876 - accuracy: 0.8796 - val_loss: 0.3893 - val_accuracy: 0.8463\n",
            "Epoch 491/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2873 - accuracy: 0.8804 - val_loss: 0.3842 - val_accuracy: 0.8489\n",
            "Epoch 492/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2851 - accuracy: 0.8783 - val_loss: 0.3843 - val_accuracy: 0.8466\n",
            "Epoch 493/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2871 - accuracy: 0.8795 - val_loss: 0.3892 - val_accuracy: 0.8444\n",
            "Epoch 494/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2863 - accuracy: 0.8793 - val_loss: 0.3857 - val_accuracy: 0.8470\n",
            "Epoch 495/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2871 - accuracy: 0.8808 - val_loss: 0.3866 - val_accuracy: 0.8489\n",
            "Epoch 496/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2848 - accuracy: 0.8808 - val_loss: 0.3898 - val_accuracy: 0.8504\n",
            "Epoch 497/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2856 - accuracy: 0.8783 - val_loss: 0.3871 - val_accuracy: 0.8485\n",
            "Epoch 498/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2841 - accuracy: 0.8787 - val_loss: 0.3860 - val_accuracy: 0.8512\n",
            "Epoch 499/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2876 - accuracy: 0.8791 - val_loss: 0.3867 - val_accuracy: 0.8451\n",
            "Epoch 500/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2865 - accuracy: 0.8791 - val_loss: 0.3851 - val_accuracy: 0.8459\n",
            "Epoch 501/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2867 - accuracy: 0.8811 - val_loss: 0.3872 - val_accuracy: 0.8436\n",
            "Epoch 502/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2857 - accuracy: 0.8783 - val_loss: 0.3858 - val_accuracy: 0.8482\n",
            "Epoch 503/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2853 - accuracy: 0.8798 - val_loss: 0.3933 - val_accuracy: 0.8459\n",
            "Epoch 504/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2849 - accuracy: 0.8806 - val_loss: 0.3917 - val_accuracy: 0.8463\n",
            "Epoch 505/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2851 - accuracy: 0.8776 - val_loss: 0.3926 - val_accuracy: 0.8501\n",
            "Epoch 506/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2859 - accuracy: 0.8780 - val_loss: 0.3876 - val_accuracy: 0.8440\n",
            "Epoch 507/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2847 - accuracy: 0.8819 - val_loss: 0.3902 - val_accuracy: 0.8478\n",
            "Epoch 508/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2861 - accuracy: 0.8809 - val_loss: 0.3925 - val_accuracy: 0.8470\n",
            "Epoch 509/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2855 - accuracy: 0.8821 - val_loss: 0.3958 - val_accuracy: 0.8436\n",
            "Epoch 510/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2849 - accuracy: 0.8804 - val_loss: 0.3877 - val_accuracy: 0.8489\n",
            "Epoch 511/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2859 - accuracy: 0.8802 - val_loss: 0.3908 - val_accuracy: 0.8470\n",
            "Epoch 512/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2862 - accuracy: 0.8800 - val_loss: 0.3907 - val_accuracy: 0.8448\n",
            "Epoch 513/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2855 - accuracy: 0.8824 - val_loss: 0.3939 - val_accuracy: 0.8470\n",
            "Epoch 514/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2849 - accuracy: 0.8789 - val_loss: 0.3957 - val_accuracy: 0.8425\n",
            "Epoch 515/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2861 - accuracy: 0.8789 - val_loss: 0.3894 - val_accuracy: 0.8463\n",
            "Epoch 516/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2861 - accuracy: 0.8795 - val_loss: 0.3922 - val_accuracy: 0.8421\n",
            "Epoch 517/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2872 - accuracy: 0.8796 - val_loss: 0.3894 - val_accuracy: 0.8482\n",
            "Epoch 518/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2839 - accuracy: 0.8817 - val_loss: 0.3916 - val_accuracy: 0.8478\n",
            "Epoch 519/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2856 - accuracy: 0.8808 - val_loss: 0.3886 - val_accuracy: 0.8516\n",
            "Epoch 520/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2859 - accuracy: 0.8798 - val_loss: 0.3897 - val_accuracy: 0.8455\n",
            "Epoch 521/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2862 - accuracy: 0.8806 - val_loss: 0.3918 - val_accuracy: 0.8432\n",
            "Epoch 522/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2851 - accuracy: 0.8815 - val_loss: 0.3854 - val_accuracy: 0.8451\n",
            "Epoch 523/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2854 - accuracy: 0.8783 - val_loss: 0.3947 - val_accuracy: 0.8463\n",
            "Epoch 524/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2854 - accuracy: 0.8795 - val_loss: 0.3903 - val_accuracy: 0.8470\n",
            "Epoch 525/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2862 - accuracy: 0.8809 - val_loss: 0.3912 - val_accuracy: 0.8425\n",
            "Epoch 526/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2865 - accuracy: 0.8800 - val_loss: 0.3872 - val_accuracy: 0.8474\n",
            "Epoch 527/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2843 - accuracy: 0.8817 - val_loss: 0.3919 - val_accuracy: 0.8512\n",
            "Epoch 528/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2861 - accuracy: 0.8817 - val_loss: 0.3881 - val_accuracy: 0.8429\n",
            "Epoch 529/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2852 - accuracy: 0.8798 - val_loss: 0.3898 - val_accuracy: 0.8466\n",
            "Epoch 530/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2850 - accuracy: 0.8776 - val_loss: 0.3925 - val_accuracy: 0.8531\n",
            "Epoch 531/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2841 - accuracy: 0.8802 - val_loss: 0.3909 - val_accuracy: 0.8482\n",
            "Epoch 532/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2857 - accuracy: 0.8798 - val_loss: 0.3947 - val_accuracy: 0.8455\n",
            "Epoch 533/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2845 - accuracy: 0.8800 - val_loss: 0.3905 - val_accuracy: 0.8474\n",
            "Epoch 534/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2850 - accuracy: 0.8811 - val_loss: 0.3918 - val_accuracy: 0.8466\n",
            "Epoch 535/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2848 - accuracy: 0.8793 - val_loss: 0.3885 - val_accuracy: 0.8508\n",
            "Epoch 536/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2825 - accuracy: 0.8823 - val_loss: 0.3964 - val_accuracy: 0.8436\n",
            "Epoch 537/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2854 - accuracy: 0.8791 - val_loss: 0.3921 - val_accuracy: 0.8466\n",
            "Epoch 538/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2850 - accuracy: 0.8811 - val_loss: 0.3914 - val_accuracy: 0.8501\n",
            "Epoch 539/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2856 - accuracy: 0.8809 - val_loss: 0.3912 - val_accuracy: 0.8482\n",
            "Epoch 540/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2863 - accuracy: 0.8789 - val_loss: 0.3974 - val_accuracy: 0.8463\n",
            "Epoch 541/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2846 - accuracy: 0.8802 - val_loss: 0.3939 - val_accuracy: 0.8448\n",
            "Epoch 542/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2850 - accuracy: 0.8791 - val_loss: 0.3927 - val_accuracy: 0.8413\n",
            "Epoch 543/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2843 - accuracy: 0.8791 - val_loss: 0.3904 - val_accuracy: 0.8493\n",
            "Epoch 544/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2851 - accuracy: 0.8800 - val_loss: 0.4002 - val_accuracy: 0.8379\n",
            "Epoch 545/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2862 - accuracy: 0.8806 - val_loss: 0.3935 - val_accuracy: 0.8421\n",
            "Epoch 546/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2845 - accuracy: 0.8800 - val_loss: 0.3919 - val_accuracy: 0.8463\n",
            "Epoch 547/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2856 - accuracy: 0.8770 - val_loss: 0.3923 - val_accuracy: 0.8459\n",
            "Epoch 548/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2844 - accuracy: 0.8815 - val_loss: 0.3900 - val_accuracy: 0.8489\n",
            "Epoch 549/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2861 - accuracy: 0.8774 - val_loss: 0.3933 - val_accuracy: 0.8432\n",
            "Epoch 550/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2852 - accuracy: 0.8781 - val_loss: 0.3995 - val_accuracy: 0.8379\n",
            "Epoch 551/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2856 - accuracy: 0.8806 - val_loss: 0.3920 - val_accuracy: 0.8451\n",
            "Epoch 552/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2846 - accuracy: 0.8804 - val_loss: 0.3915 - val_accuracy: 0.8497\n",
            "Epoch 553/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2845 - accuracy: 0.8826 - val_loss: 0.3992 - val_accuracy: 0.8413\n",
            "Epoch 554/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2845 - accuracy: 0.8789 - val_loss: 0.3955 - val_accuracy: 0.8444\n",
            "Epoch 555/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2854 - accuracy: 0.8785 - val_loss: 0.3935 - val_accuracy: 0.8485\n",
            "Epoch 556/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2841 - accuracy: 0.8798 - val_loss: 0.3879 - val_accuracy: 0.8497\n",
            "Epoch 557/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2850 - accuracy: 0.8804 - val_loss: 0.3927 - val_accuracy: 0.8463\n",
            "Epoch 558/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2845 - accuracy: 0.8811 - val_loss: 0.3941 - val_accuracy: 0.8482\n",
            "Epoch 559/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2843 - accuracy: 0.8809 - val_loss: 0.3944 - val_accuracy: 0.8501\n",
            "Epoch 560/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2853 - accuracy: 0.8783 - val_loss: 0.3914 - val_accuracy: 0.8451\n",
            "Epoch 561/1000\n",
            "536/536 [==============================] - 4s 7ms/step - loss: 0.2851 - accuracy: 0.8796 - val_loss: 0.3900 - val_accuracy: 0.8508\n",
            "Epoch 562/1000\n",
            "536/536 [==============================] - 4s 7ms/step - loss: 0.2837 - accuracy: 0.8830 - val_loss: 0.3954 - val_accuracy: 0.8432\n",
            "Epoch 563/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.2847 - accuracy: 0.8808 - val_loss: 0.3937 - val_accuracy: 0.8463\n",
            "Epoch 564/1000\n",
            "536/536 [==============================] - 4s 7ms/step - loss: 0.2837 - accuracy: 0.8770 - val_loss: 0.4022 - val_accuracy: 0.8550\n",
            "Epoch 565/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2837 - accuracy: 0.8804 - val_loss: 0.3920 - val_accuracy: 0.8455\n",
            "Epoch 566/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2839 - accuracy: 0.8832 - val_loss: 0.3996 - val_accuracy: 0.8466\n",
            "Epoch 567/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2836 - accuracy: 0.8837 - val_loss: 0.3961 - val_accuracy: 0.8425\n",
            "Epoch 568/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2847 - accuracy: 0.8804 - val_loss: 0.4081 - val_accuracy: 0.8402\n",
            "Epoch 569/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2846 - accuracy: 0.8791 - val_loss: 0.3971 - val_accuracy: 0.8413\n",
            "Epoch 570/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2848 - accuracy: 0.8804 - val_loss: 0.3928 - val_accuracy: 0.8482\n",
            "Epoch 571/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2845 - accuracy: 0.8811 - val_loss: 0.3914 - val_accuracy: 0.8485\n",
            "Epoch 572/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2859 - accuracy: 0.8809 - val_loss: 0.3901 - val_accuracy: 0.8493\n",
            "Epoch 573/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2838 - accuracy: 0.8804 - val_loss: 0.3973 - val_accuracy: 0.8504\n",
            "Epoch 574/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2849 - accuracy: 0.8804 - val_loss: 0.3919 - val_accuracy: 0.8474\n",
            "Epoch 575/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2825 - accuracy: 0.8809 - val_loss: 0.3934 - val_accuracy: 0.8527\n",
            "Epoch 576/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2866 - accuracy: 0.8796 - val_loss: 0.3959 - val_accuracy: 0.8493\n",
            "Epoch 577/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2852 - accuracy: 0.8808 - val_loss: 0.3909 - val_accuracy: 0.8470\n",
            "Epoch 578/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2842 - accuracy: 0.8787 - val_loss: 0.3957 - val_accuracy: 0.8497\n",
            "Epoch 579/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2855 - accuracy: 0.8798 - val_loss: 0.3944 - val_accuracy: 0.8425\n",
            "Epoch 580/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2827 - accuracy: 0.8808 - val_loss: 0.3959 - val_accuracy: 0.8470\n",
            "Epoch 581/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2838 - accuracy: 0.8796 - val_loss: 0.4009 - val_accuracy: 0.8391\n",
            "Epoch 582/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2850 - accuracy: 0.8815 - val_loss: 0.3943 - val_accuracy: 0.8429\n",
            "Epoch 583/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2836 - accuracy: 0.8815 - val_loss: 0.4059 - val_accuracy: 0.8444\n",
            "Epoch 584/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2835 - accuracy: 0.8798 - val_loss: 0.4007 - val_accuracy: 0.8421\n",
            "Epoch 585/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2849 - accuracy: 0.8808 - val_loss: 0.3911 - val_accuracy: 0.8440\n",
            "Epoch 586/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2822 - accuracy: 0.8824 - val_loss: 0.3963 - val_accuracy: 0.8501\n",
            "Epoch 587/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2842 - accuracy: 0.8823 - val_loss: 0.4029 - val_accuracy: 0.8466\n",
            "Epoch 588/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2837 - accuracy: 0.8800 - val_loss: 0.3976 - val_accuracy: 0.8478\n",
            "Epoch 589/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2855 - accuracy: 0.8796 - val_loss: 0.4015 - val_accuracy: 0.8466\n",
            "Epoch 590/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2834 - accuracy: 0.8809 - val_loss: 0.3927 - val_accuracy: 0.8470\n",
            "Epoch 591/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2850 - accuracy: 0.8826 - val_loss: 0.3947 - val_accuracy: 0.8470\n",
            "Epoch 592/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2839 - accuracy: 0.8821 - val_loss: 0.3948 - val_accuracy: 0.8531\n",
            "Epoch 593/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2853 - accuracy: 0.8821 - val_loss: 0.3933 - val_accuracy: 0.8451\n",
            "Epoch 594/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2844 - accuracy: 0.8800 - val_loss: 0.3908 - val_accuracy: 0.8474\n",
            "Epoch 595/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2847 - accuracy: 0.8800 - val_loss: 0.3941 - val_accuracy: 0.8448\n",
            "Epoch 596/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2842 - accuracy: 0.8813 - val_loss: 0.3976 - val_accuracy: 0.8459\n",
            "Epoch 597/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2839 - accuracy: 0.8824 - val_loss: 0.3928 - val_accuracy: 0.8432\n",
            "Epoch 598/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.2836 - accuracy: 0.8811 - val_loss: 0.3963 - val_accuracy: 0.8516\n",
            "Epoch 599/1000\n",
            "536/536 [==============================] - 3s 6ms/step - loss: 0.2828 - accuracy: 0.8806 - val_loss: 0.4001 - val_accuracy: 0.8478\n",
            "Epoch 600/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2844 - accuracy: 0.8809 - val_loss: 0.3998 - val_accuracy: 0.8425\n",
            "Epoch 601/1000\n",
            "536/536 [==============================] - 4s 7ms/step - loss: 0.2846 - accuracy: 0.8815 - val_loss: 0.3920 - val_accuracy: 0.8470\n",
            "Epoch 602/1000\n",
            "536/536 [==============================] - 4s 7ms/step - loss: 0.2844 - accuracy: 0.8804 - val_loss: 0.3936 - val_accuracy: 0.8478\n",
            "Epoch 603/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2826 - accuracy: 0.8836 - val_loss: 0.3985 - val_accuracy: 0.8478\n",
            "Epoch 604/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2848 - accuracy: 0.8823 - val_loss: 0.3906 - val_accuracy: 0.8497\n",
            "Epoch 605/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2832 - accuracy: 0.8826 - val_loss: 0.3904 - val_accuracy: 0.8436\n",
            "Epoch 606/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2843 - accuracy: 0.8826 - val_loss: 0.3952 - val_accuracy: 0.8455\n",
            "Epoch 607/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2830 - accuracy: 0.8821 - val_loss: 0.3904 - val_accuracy: 0.8478\n",
            "Epoch 608/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2843 - accuracy: 0.8795 - val_loss: 0.3959 - val_accuracy: 0.8463\n",
            "Epoch 609/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2832 - accuracy: 0.8832 - val_loss: 0.3986 - val_accuracy: 0.8455\n",
            "Epoch 610/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2844 - accuracy: 0.8808 - val_loss: 0.3978 - val_accuracy: 0.8440\n",
            "Epoch 611/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2843 - accuracy: 0.8802 - val_loss: 0.3937 - val_accuracy: 0.8474\n",
            "Epoch 612/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2831 - accuracy: 0.8826 - val_loss: 0.3947 - val_accuracy: 0.8493\n",
            "Epoch 613/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2838 - accuracy: 0.8811 - val_loss: 0.3991 - val_accuracy: 0.8432\n",
            "Epoch 614/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2840 - accuracy: 0.8817 - val_loss: 0.4019 - val_accuracy: 0.8482\n",
            "Epoch 615/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.2849 - accuracy: 0.8813 - val_loss: 0.3986 - val_accuracy: 0.8501\n",
            "Epoch 616/1000\n",
            "536/536 [==============================] - 4s 7ms/step - loss: 0.2841 - accuracy: 0.8834 - val_loss: 0.3936 - val_accuracy: 0.8485\n",
            "Epoch 617/1000\n",
            "536/536 [==============================] - 3s 6ms/step - loss: 0.2847 - accuracy: 0.8804 - val_loss: 0.3979 - val_accuracy: 0.8451\n",
            "Epoch 618/1000\n",
            "536/536 [==============================] - 3s 6ms/step - loss: 0.2830 - accuracy: 0.8841 - val_loss: 0.3947 - val_accuracy: 0.8459\n",
            "Epoch 619/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.2860 - accuracy: 0.8802 - val_loss: 0.3952 - val_accuracy: 0.8455\n",
            "Epoch 620/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2855 - accuracy: 0.8813 - val_loss: 0.3952 - val_accuracy: 0.8425\n",
            "Epoch 621/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2836 - accuracy: 0.8798 - val_loss: 0.3962 - val_accuracy: 0.8413\n",
            "Epoch 622/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2833 - accuracy: 0.8815 - val_loss: 0.3943 - val_accuracy: 0.8432\n",
            "Epoch 623/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2829 - accuracy: 0.8819 - val_loss: 0.4031 - val_accuracy: 0.8482\n",
            "Epoch 624/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.2837 - accuracy: 0.8819 - val_loss: 0.4059 - val_accuracy: 0.8391\n",
            "Epoch 625/1000\n",
            "536/536 [==============================] - 3s 6ms/step - loss: 0.2839 - accuracy: 0.8809 - val_loss: 0.4050 - val_accuracy: 0.8379\n",
            "Epoch 626/1000\n",
            "536/536 [==============================] - 3s 6ms/step - loss: 0.2842 - accuracy: 0.8826 - val_loss: 0.3911 - val_accuracy: 0.8482\n",
            "Epoch 627/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2841 - accuracy: 0.8800 - val_loss: 0.3989 - val_accuracy: 0.8432\n",
            "Epoch 628/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2839 - accuracy: 0.8798 - val_loss: 0.3981 - val_accuracy: 0.8429\n",
            "Epoch 629/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2837 - accuracy: 0.8819 - val_loss: 0.4016 - val_accuracy: 0.8440\n",
            "Epoch 630/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2847 - accuracy: 0.8819 - val_loss: 0.3958 - val_accuracy: 0.8436\n",
            "Epoch 631/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2847 - accuracy: 0.8795 - val_loss: 0.3965 - val_accuracy: 0.8459\n",
            "Epoch 632/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2839 - accuracy: 0.8809 - val_loss: 0.3934 - val_accuracy: 0.8429\n",
            "Epoch 633/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2834 - accuracy: 0.8808 - val_loss: 0.3975 - val_accuracy: 0.8436\n",
            "Epoch 634/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2833 - accuracy: 0.8806 - val_loss: 0.3912 - val_accuracy: 0.8455\n",
            "Epoch 635/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2844 - accuracy: 0.8804 - val_loss: 0.3947 - val_accuracy: 0.8417\n",
            "Epoch 636/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2821 - accuracy: 0.8836 - val_loss: 0.4065 - val_accuracy: 0.8417\n",
            "Epoch 637/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2839 - accuracy: 0.8798 - val_loss: 0.4014 - val_accuracy: 0.8395\n",
            "Epoch 638/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2829 - accuracy: 0.8789 - val_loss: 0.4015 - val_accuracy: 0.8429\n",
            "Epoch 639/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2835 - accuracy: 0.8796 - val_loss: 0.3902 - val_accuracy: 0.8459\n",
            "Epoch 640/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2834 - accuracy: 0.8852 - val_loss: 0.3977 - val_accuracy: 0.8417\n",
            "Epoch 641/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2841 - accuracy: 0.8808 - val_loss: 0.4023 - val_accuracy: 0.8436\n",
            "Epoch 642/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2830 - accuracy: 0.8836 - val_loss: 0.3969 - val_accuracy: 0.8516\n",
            "Epoch 643/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2852 - accuracy: 0.8804 - val_loss: 0.3952 - val_accuracy: 0.8478\n",
            "Epoch 644/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2825 - accuracy: 0.8796 - val_loss: 0.3967 - val_accuracy: 0.8482\n",
            "Epoch 645/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.2829 - accuracy: 0.8817 - val_loss: 0.3988 - val_accuracy: 0.8459\n",
            "Epoch 646/1000\n",
            "536/536 [==============================] - 3s 6ms/step - loss: 0.2826 - accuracy: 0.8836 - val_loss: 0.3933 - val_accuracy: 0.8436\n",
            "Epoch 647/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.2835 - accuracy: 0.8800 - val_loss: 0.3933 - val_accuracy: 0.8512\n",
            "Epoch 648/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2842 - accuracy: 0.8813 - val_loss: 0.3940 - val_accuracy: 0.8451\n",
            "Epoch 649/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2840 - accuracy: 0.8802 - val_loss: 0.3918 - val_accuracy: 0.8489\n",
            "Epoch 650/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2849 - accuracy: 0.8808 - val_loss: 0.4002 - val_accuracy: 0.8383\n",
            "Epoch 651/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2840 - accuracy: 0.8806 - val_loss: 0.3938 - val_accuracy: 0.8466\n",
            "Epoch 652/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2840 - accuracy: 0.8830 - val_loss: 0.3965 - val_accuracy: 0.8459\n",
            "Epoch 653/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2837 - accuracy: 0.8819 - val_loss: 0.3938 - val_accuracy: 0.8432\n",
            "Epoch 654/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2834 - accuracy: 0.8802 - val_loss: 0.3942 - val_accuracy: 0.8429\n",
            "Epoch 655/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2842 - accuracy: 0.8817 - val_loss: 0.4063 - val_accuracy: 0.8379\n",
            "Epoch 656/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2840 - accuracy: 0.8800 - val_loss: 0.3969 - val_accuracy: 0.8448\n",
            "Epoch 657/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2836 - accuracy: 0.8804 - val_loss: 0.3966 - val_accuracy: 0.8470\n",
            "Epoch 658/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2831 - accuracy: 0.8815 - val_loss: 0.3948 - val_accuracy: 0.8463\n",
            "Epoch 659/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2835 - accuracy: 0.8811 - val_loss: 0.3972 - val_accuracy: 0.8470\n",
            "Epoch 660/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2853 - accuracy: 0.8819 - val_loss: 0.3974 - val_accuracy: 0.8466\n",
            "Epoch 661/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2826 - accuracy: 0.8802 - val_loss: 0.3946 - val_accuracy: 0.8466\n",
            "Epoch 662/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2835 - accuracy: 0.8809 - val_loss: 0.3979 - val_accuracy: 0.8466\n",
            "Epoch 663/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2823 - accuracy: 0.8815 - val_loss: 0.3997 - val_accuracy: 0.8448\n",
            "Epoch 664/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2825 - accuracy: 0.8811 - val_loss: 0.3978 - val_accuracy: 0.8448\n",
            "Epoch 665/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2824 - accuracy: 0.8837 - val_loss: 0.4006 - val_accuracy: 0.8466\n",
            "Epoch 666/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2830 - accuracy: 0.8802 - val_loss: 0.4048 - val_accuracy: 0.8410\n",
            "Epoch 667/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2847 - accuracy: 0.8824 - val_loss: 0.3974 - val_accuracy: 0.8478\n",
            "Epoch 668/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2845 - accuracy: 0.8824 - val_loss: 0.4076 - val_accuracy: 0.8368\n",
            "Epoch 669/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2825 - accuracy: 0.8798 - val_loss: 0.3952 - val_accuracy: 0.8410\n",
            "Epoch 670/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2831 - accuracy: 0.8806 - val_loss: 0.4049 - val_accuracy: 0.8425\n",
            "Epoch 671/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2825 - accuracy: 0.8811 - val_loss: 0.4001 - val_accuracy: 0.8429\n",
            "Epoch 672/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2830 - accuracy: 0.8823 - val_loss: 0.4026 - val_accuracy: 0.8395\n",
            "Epoch 673/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2839 - accuracy: 0.8802 - val_loss: 0.4059 - val_accuracy: 0.8398\n",
            "Epoch 674/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2828 - accuracy: 0.8847 - val_loss: 0.4034 - val_accuracy: 0.8425\n",
            "Epoch 675/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2835 - accuracy: 0.8798 - val_loss: 0.3990 - val_accuracy: 0.8429\n",
            "Epoch 676/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2832 - accuracy: 0.8834 - val_loss: 0.3932 - val_accuracy: 0.8425\n",
            "Epoch 677/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2836 - accuracy: 0.8808 - val_loss: 0.3958 - val_accuracy: 0.8432\n",
            "Epoch 678/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2852 - accuracy: 0.8798 - val_loss: 0.3947 - val_accuracy: 0.8497\n",
            "Epoch 679/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2854 - accuracy: 0.8808 - val_loss: 0.3953 - val_accuracy: 0.8444\n",
            "Epoch 680/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2836 - accuracy: 0.8815 - val_loss: 0.3899 - val_accuracy: 0.8455\n",
            "Epoch 681/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2839 - accuracy: 0.8823 - val_loss: 0.3972 - val_accuracy: 0.8512\n",
            "Epoch 682/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2818 - accuracy: 0.8819 - val_loss: 0.4048 - val_accuracy: 0.8489\n",
            "Epoch 683/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2835 - accuracy: 0.8824 - val_loss: 0.3969 - val_accuracy: 0.8413\n",
            "Epoch 684/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2831 - accuracy: 0.8815 - val_loss: 0.3942 - val_accuracy: 0.8429\n",
            "Epoch 685/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2846 - accuracy: 0.8817 - val_loss: 0.3964 - val_accuracy: 0.8440\n",
            "Epoch 686/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2804 - accuracy: 0.8811 - val_loss: 0.3968 - val_accuracy: 0.8451\n",
            "Epoch 687/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2844 - accuracy: 0.8826 - val_loss: 0.3972 - val_accuracy: 0.8444\n",
            "Epoch 688/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2841 - accuracy: 0.8778 - val_loss: 0.3999 - val_accuracy: 0.8391\n",
            "Epoch 689/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.2839 - accuracy: 0.8800 - val_loss: 0.3923 - val_accuracy: 0.8489\n",
            "Epoch 690/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2828 - accuracy: 0.8834 - val_loss: 0.3991 - val_accuracy: 0.8527\n",
            "Epoch 691/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2824 - accuracy: 0.8824 - val_loss: 0.3900 - val_accuracy: 0.8466\n",
            "Epoch 692/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2821 - accuracy: 0.8815 - val_loss: 0.4004 - val_accuracy: 0.8432\n",
            "Epoch 693/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2839 - accuracy: 0.8809 - val_loss: 0.3962 - val_accuracy: 0.8512\n",
            "Epoch 694/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2835 - accuracy: 0.8836 - val_loss: 0.3955 - val_accuracy: 0.8478\n",
            "Epoch 695/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2839 - accuracy: 0.8811 - val_loss: 0.3993 - val_accuracy: 0.8512\n",
            "Epoch 696/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2825 - accuracy: 0.8834 - val_loss: 0.4026 - val_accuracy: 0.8425\n",
            "Epoch 697/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2834 - accuracy: 0.8817 - val_loss: 0.3981 - val_accuracy: 0.8516\n",
            "Epoch 698/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2817 - accuracy: 0.8809 - val_loss: 0.4011 - val_accuracy: 0.8436\n",
            "Epoch 699/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2838 - accuracy: 0.8836 - val_loss: 0.3955 - val_accuracy: 0.8482\n",
            "Epoch 700/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2834 - accuracy: 0.8815 - val_loss: 0.3941 - val_accuracy: 0.8478\n",
            "Epoch 701/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2834 - accuracy: 0.8821 - val_loss: 0.3969 - val_accuracy: 0.8493\n",
            "Epoch 702/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2840 - accuracy: 0.8800 - val_loss: 0.3983 - val_accuracy: 0.8429\n",
            "Epoch 703/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2822 - accuracy: 0.8811 - val_loss: 0.4047 - val_accuracy: 0.8342\n",
            "Epoch 704/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2820 - accuracy: 0.8809 - val_loss: 0.4008 - val_accuracy: 0.8395\n",
            "Epoch 705/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2835 - accuracy: 0.8809 - val_loss: 0.4010 - val_accuracy: 0.8485\n",
            "Epoch 706/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2838 - accuracy: 0.8821 - val_loss: 0.3977 - val_accuracy: 0.8436\n",
            "Epoch 707/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2836 - accuracy: 0.8828 - val_loss: 0.4005 - val_accuracy: 0.8432\n",
            "Epoch 708/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.2816 - accuracy: 0.8826 - val_loss: 0.4028 - val_accuracy: 0.8463\n",
            "Epoch 709/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.2819 - accuracy: 0.8832 - val_loss: 0.4044 - val_accuracy: 0.8395\n",
            "Epoch 710/1000\n",
            "536/536 [==============================] - 3s 6ms/step - loss: 0.2830 - accuracy: 0.8815 - val_loss: 0.3963 - val_accuracy: 0.8432\n",
            "Epoch 711/1000\n",
            "536/536 [==============================] - 3s 6ms/step - loss: 0.2824 - accuracy: 0.8813 - val_loss: 0.3982 - val_accuracy: 0.8440\n",
            "Epoch 712/1000\n",
            "536/536 [==============================] - 4s 7ms/step - loss: 0.2836 - accuracy: 0.8802 - val_loss: 0.4005 - val_accuracy: 0.8466\n",
            "Epoch 713/1000\n",
            "536/536 [==============================] - 4s 7ms/step - loss: 0.2809 - accuracy: 0.8839 - val_loss: 0.3991 - val_accuracy: 0.8421\n",
            "Epoch 714/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2822 - accuracy: 0.8826 - val_loss: 0.3933 - val_accuracy: 0.8501\n",
            "Epoch 715/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2831 - accuracy: 0.8837 - val_loss: 0.4011 - val_accuracy: 0.8398\n",
            "Epoch 716/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2838 - accuracy: 0.8815 - val_loss: 0.3948 - val_accuracy: 0.8459\n",
            "Epoch 717/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2825 - accuracy: 0.8826 - val_loss: 0.3947 - val_accuracy: 0.8482\n",
            "Epoch 718/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2822 - accuracy: 0.8845 - val_loss: 0.3985 - val_accuracy: 0.8482\n",
            "Epoch 719/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2831 - accuracy: 0.8809 - val_loss: 0.3920 - val_accuracy: 0.8478\n",
            "Epoch 720/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2835 - accuracy: 0.8813 - val_loss: 0.3946 - val_accuracy: 0.8444\n",
            "Epoch 721/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2829 - accuracy: 0.8819 - val_loss: 0.3955 - val_accuracy: 0.8410\n",
            "Epoch 722/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2831 - accuracy: 0.8776 - val_loss: 0.4051 - val_accuracy: 0.8357\n",
            "Epoch 723/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2834 - accuracy: 0.8813 - val_loss: 0.3952 - val_accuracy: 0.8448\n",
            "Epoch 724/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2821 - accuracy: 0.8830 - val_loss: 0.3973 - val_accuracy: 0.8474\n",
            "Epoch 725/1000\n",
            "536/536 [==============================] - 3s 6ms/step - loss: 0.2830 - accuracy: 0.8806 - val_loss: 0.3976 - val_accuracy: 0.8410\n",
            "Epoch 726/1000\n",
            "536/536 [==============================] - 3s 6ms/step - loss: 0.2826 - accuracy: 0.8819 - val_loss: 0.3960 - val_accuracy: 0.8463\n",
            "Epoch 727/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.2844 - accuracy: 0.8806 - val_loss: 0.3958 - val_accuracy: 0.8444\n",
            "Epoch 728/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2823 - accuracy: 0.8811 - val_loss: 0.4038 - val_accuracy: 0.8497\n",
            "Epoch 729/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2842 - accuracy: 0.8819 - val_loss: 0.3938 - val_accuracy: 0.8402\n",
            "Epoch 730/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2824 - accuracy: 0.8821 - val_loss: 0.4038 - val_accuracy: 0.8493\n",
            "Epoch 731/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2832 - accuracy: 0.8804 - val_loss: 0.4004 - val_accuracy: 0.8432\n",
            "Epoch 732/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2838 - accuracy: 0.8806 - val_loss: 0.3961 - val_accuracy: 0.8395\n",
            "Epoch 733/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2808 - accuracy: 0.8839 - val_loss: 0.3972 - val_accuracy: 0.8444\n",
            "Epoch 734/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2838 - accuracy: 0.8837 - val_loss: 0.3985 - val_accuracy: 0.8493\n",
            "Epoch 735/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.2820 - accuracy: 0.8832 - val_loss: 0.4079 - val_accuracy: 0.8406\n",
            "Epoch 736/1000\n",
            "536/536 [==============================] - 3s 6ms/step - loss: 0.2834 - accuracy: 0.8841 - val_loss: 0.4037 - val_accuracy: 0.8413\n",
            "Epoch 737/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.2839 - accuracy: 0.8804 - val_loss: 0.3971 - val_accuracy: 0.8429\n",
            "Epoch 738/1000\n",
            "536/536 [==============================] - 3s 6ms/step - loss: 0.2833 - accuracy: 0.8802 - val_loss: 0.4025 - val_accuracy: 0.8485\n",
            "Epoch 739/1000\n",
            "536/536 [==============================] - 4s 7ms/step - loss: 0.2841 - accuracy: 0.8815 - val_loss: 0.3984 - val_accuracy: 0.8478\n",
            "Epoch 740/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2820 - accuracy: 0.8832 - val_loss: 0.3990 - val_accuracy: 0.8478\n",
            "Epoch 741/1000\n",
            "536/536 [==============================] - 3s 6ms/step - loss: 0.2834 - accuracy: 0.8802 - val_loss: 0.3977 - val_accuracy: 0.8466\n",
            "Epoch 742/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2827 - accuracy: 0.8809 - val_loss: 0.3987 - val_accuracy: 0.8482\n",
            "Epoch 743/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2831 - accuracy: 0.8800 - val_loss: 0.3934 - val_accuracy: 0.8474\n",
            "Epoch 744/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2824 - accuracy: 0.8851 - val_loss: 0.4002 - val_accuracy: 0.8485\n",
            "Epoch 745/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2819 - accuracy: 0.8832 - val_loss: 0.3963 - val_accuracy: 0.8421\n",
            "Epoch 746/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2845 - accuracy: 0.8804 - val_loss: 0.3970 - val_accuracy: 0.8470\n",
            "Epoch 747/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2822 - accuracy: 0.8800 - val_loss: 0.3955 - val_accuracy: 0.8478\n",
            "Epoch 748/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.2828 - accuracy: 0.8836 - val_loss: 0.3962 - val_accuracy: 0.8459\n",
            "Epoch 749/1000\n",
            "536/536 [==============================] - 3s 6ms/step - loss: 0.2824 - accuracy: 0.8852 - val_loss: 0.3944 - val_accuracy: 0.8444\n",
            "Epoch 750/1000\n",
            "536/536 [==============================] - 3s 6ms/step - loss: 0.2819 - accuracy: 0.8834 - val_loss: 0.3989 - val_accuracy: 0.8482\n",
            "Epoch 751/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2839 - accuracy: 0.8817 - val_loss: 0.3972 - val_accuracy: 0.8413\n",
            "Epoch 752/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2838 - accuracy: 0.8821 - val_loss: 0.3965 - val_accuracy: 0.8444\n",
            "Epoch 753/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2827 - accuracy: 0.8843 - val_loss: 0.3983 - val_accuracy: 0.8451\n",
            "Epoch 754/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.2840 - accuracy: 0.8832 - val_loss: 0.4006 - val_accuracy: 0.8410\n",
            "Epoch 755/1000\n",
            "536/536 [==============================] - 4s 7ms/step - loss: 0.2811 - accuracy: 0.8796 - val_loss: 0.4024 - val_accuracy: 0.8512\n",
            "Epoch 756/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2820 - accuracy: 0.8832 - val_loss: 0.3984 - val_accuracy: 0.8425\n",
            "Epoch 757/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2828 - accuracy: 0.8796 - val_loss: 0.3996 - val_accuracy: 0.8455\n",
            "Epoch 758/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2831 - accuracy: 0.8836 - val_loss: 0.3961 - val_accuracy: 0.8413\n",
            "Epoch 759/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2811 - accuracy: 0.8811 - val_loss: 0.4060 - val_accuracy: 0.8391\n",
            "Epoch 760/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2842 - accuracy: 0.8830 - val_loss: 0.3980 - val_accuracy: 0.8417\n",
            "Epoch 761/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2838 - accuracy: 0.8823 - val_loss: 0.3995 - val_accuracy: 0.8482\n",
            "Epoch 762/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2828 - accuracy: 0.8819 - val_loss: 0.3992 - val_accuracy: 0.8459\n",
            "Epoch 763/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2836 - accuracy: 0.8815 - val_loss: 0.3966 - val_accuracy: 0.8444\n",
            "Epoch 764/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2837 - accuracy: 0.8817 - val_loss: 0.3970 - val_accuracy: 0.8444\n",
            "Epoch 765/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2822 - accuracy: 0.8834 - val_loss: 0.3999 - val_accuracy: 0.8436\n",
            "Epoch 766/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2828 - accuracy: 0.8811 - val_loss: 0.3999 - val_accuracy: 0.8485\n",
            "Epoch 767/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2828 - accuracy: 0.8828 - val_loss: 0.3938 - val_accuracy: 0.8444\n",
            "Epoch 768/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2824 - accuracy: 0.8837 - val_loss: 0.3967 - val_accuracy: 0.8402\n",
            "Epoch 769/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2829 - accuracy: 0.8828 - val_loss: 0.4000 - val_accuracy: 0.8448\n",
            "Epoch 770/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2823 - accuracy: 0.8832 - val_loss: 0.3988 - val_accuracy: 0.8413\n",
            "Epoch 771/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2825 - accuracy: 0.8809 - val_loss: 0.3998 - val_accuracy: 0.8501\n",
            "Epoch 772/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2836 - accuracy: 0.8856 - val_loss: 0.3982 - val_accuracy: 0.8459\n",
            "Epoch 773/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2821 - accuracy: 0.8819 - val_loss: 0.3963 - val_accuracy: 0.8493\n",
            "Epoch 774/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2839 - accuracy: 0.8808 - val_loss: 0.3984 - val_accuracy: 0.8512\n",
            "Epoch 775/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2818 - accuracy: 0.8830 - val_loss: 0.4007 - val_accuracy: 0.8421\n",
            "Epoch 776/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2821 - accuracy: 0.8839 - val_loss: 0.4004 - val_accuracy: 0.8519\n",
            "Epoch 777/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2824 - accuracy: 0.8819 - val_loss: 0.3947 - val_accuracy: 0.8455\n",
            "Epoch 778/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2830 - accuracy: 0.8811 - val_loss: 0.4000 - val_accuracy: 0.8440\n",
            "Epoch 779/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2818 - accuracy: 0.8832 - val_loss: 0.3993 - val_accuracy: 0.8436\n",
            "Epoch 780/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2841 - accuracy: 0.8811 - val_loss: 0.3997 - val_accuracy: 0.8455\n",
            "Epoch 781/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2815 - accuracy: 0.8834 - val_loss: 0.4014 - val_accuracy: 0.8519\n",
            "Epoch 782/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2830 - accuracy: 0.8795 - val_loss: 0.3997 - val_accuracy: 0.8489\n",
            "Epoch 783/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2834 - accuracy: 0.8813 - val_loss: 0.4013 - val_accuracy: 0.8444\n",
            "Epoch 784/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2831 - accuracy: 0.8826 - val_loss: 0.3970 - val_accuracy: 0.8451\n",
            "Epoch 785/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2843 - accuracy: 0.8813 - val_loss: 0.4025 - val_accuracy: 0.8455\n",
            "Epoch 786/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2822 - accuracy: 0.8839 - val_loss: 0.4032 - val_accuracy: 0.8372\n",
            "Epoch 787/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2813 - accuracy: 0.8821 - val_loss: 0.4004 - val_accuracy: 0.8448\n",
            "Epoch 788/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2824 - accuracy: 0.8817 - val_loss: 0.4055 - val_accuracy: 0.8364\n",
            "Epoch 789/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2822 - accuracy: 0.8811 - val_loss: 0.3985 - val_accuracy: 0.8459\n",
            "Epoch 790/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2826 - accuracy: 0.8845 - val_loss: 0.4046 - val_accuracy: 0.8463\n",
            "Epoch 791/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2825 - accuracy: 0.8813 - val_loss: 0.3979 - val_accuracy: 0.8463\n",
            "Epoch 792/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2818 - accuracy: 0.8826 - val_loss: 0.4015 - val_accuracy: 0.8429\n",
            "Epoch 793/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2829 - accuracy: 0.8802 - val_loss: 0.3952 - val_accuracy: 0.8519\n",
            "Epoch 794/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2849 - accuracy: 0.8809 - val_loss: 0.3964 - val_accuracy: 0.8516\n",
            "Epoch 795/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2826 - accuracy: 0.8834 - val_loss: 0.3985 - val_accuracy: 0.8493\n",
            "Epoch 796/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2835 - accuracy: 0.8809 - val_loss: 0.3965 - val_accuracy: 0.8451\n",
            "Epoch 797/1000\n",
            "536/536 [==============================] - 4s 7ms/step - loss: 0.2812 - accuracy: 0.8819 - val_loss: 0.4023 - val_accuracy: 0.8466\n",
            "Epoch 798/1000\n",
            "536/536 [==============================] - 3s 6ms/step - loss: 0.2830 - accuracy: 0.8796 - val_loss: 0.3954 - val_accuracy: 0.8489\n",
            "Epoch 799/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2832 - accuracy: 0.8806 - val_loss: 0.4039 - val_accuracy: 0.8474\n",
            "Epoch 800/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2847 - accuracy: 0.8798 - val_loss: 0.3977 - val_accuracy: 0.8417\n",
            "Epoch 801/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2839 - accuracy: 0.8778 - val_loss: 0.3991 - val_accuracy: 0.8466\n",
            "Epoch 802/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2832 - accuracy: 0.8791 - val_loss: 0.3978 - val_accuracy: 0.8463\n",
            "Epoch 803/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2821 - accuracy: 0.8836 - val_loss: 0.4045 - val_accuracy: 0.8436\n",
            "Epoch 804/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2829 - accuracy: 0.8806 - val_loss: 0.3949 - val_accuracy: 0.8482\n",
            "Epoch 805/1000\n",
            "536/536 [==============================] - 3s 6ms/step - loss: 0.2840 - accuracy: 0.8806 - val_loss: 0.4011 - val_accuracy: 0.8432\n",
            "Epoch 806/1000\n",
            "536/536 [==============================] - 3s 6ms/step - loss: 0.2829 - accuracy: 0.8798 - val_loss: 0.3988 - val_accuracy: 0.8470\n",
            "Epoch 807/1000\n",
            "536/536 [==============================] - 3s 6ms/step - loss: 0.2853 - accuracy: 0.8770 - val_loss: 0.3957 - val_accuracy: 0.8478\n",
            "Epoch 808/1000\n",
            "536/536 [==============================] - 4s 7ms/step - loss: 0.2814 - accuracy: 0.8834 - val_loss: 0.3996 - val_accuracy: 0.8444\n",
            "Epoch 809/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2821 - accuracy: 0.8824 - val_loss: 0.3965 - val_accuracy: 0.8459\n",
            "Epoch 810/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2823 - accuracy: 0.8837 - val_loss: 0.4127 - val_accuracy: 0.8387\n",
            "Epoch 811/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2835 - accuracy: 0.8839 - val_loss: 0.3964 - val_accuracy: 0.8463\n",
            "Epoch 812/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2826 - accuracy: 0.8811 - val_loss: 0.3988 - val_accuracy: 0.8451\n",
            "Epoch 813/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2816 - accuracy: 0.8828 - val_loss: 0.3946 - val_accuracy: 0.8459\n",
            "Epoch 814/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2809 - accuracy: 0.8837 - val_loss: 0.3997 - val_accuracy: 0.8429\n",
            "Epoch 815/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2824 - accuracy: 0.8836 - val_loss: 0.4068 - val_accuracy: 0.8440\n",
            "Epoch 816/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2823 - accuracy: 0.8800 - val_loss: 0.4116 - val_accuracy: 0.8395\n",
            "Epoch 817/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2812 - accuracy: 0.8826 - val_loss: 0.4006 - val_accuracy: 0.8482\n",
            "Epoch 818/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2835 - accuracy: 0.8821 - val_loss: 0.3991 - val_accuracy: 0.8383\n",
            "Epoch 819/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2814 - accuracy: 0.8830 - val_loss: 0.4017 - val_accuracy: 0.8353\n",
            "Epoch 820/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2823 - accuracy: 0.8809 - val_loss: 0.3982 - val_accuracy: 0.8444\n",
            "Epoch 821/1000\n",
            "536/536 [==============================] - 4s 8ms/step - loss: 0.2815 - accuracy: 0.8809 - val_loss: 0.4017 - val_accuracy: 0.8429\n",
            "Epoch 822/1000\n",
            "536/536 [==============================] - 4s 7ms/step - loss: 0.2813 - accuracy: 0.8823 - val_loss: 0.4087 - val_accuracy: 0.8372\n",
            "Epoch 823/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2830 - accuracy: 0.8804 - val_loss: 0.3969 - val_accuracy: 0.8425\n",
            "Epoch 824/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2823 - accuracy: 0.8793 - val_loss: 0.3997 - val_accuracy: 0.8448\n",
            "Epoch 825/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2835 - accuracy: 0.8806 - val_loss: 0.3986 - val_accuracy: 0.8474\n",
            "Epoch 826/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2812 - accuracy: 0.8817 - val_loss: 0.3980 - val_accuracy: 0.8402\n",
            "Epoch 827/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2827 - accuracy: 0.8808 - val_loss: 0.4121 - val_accuracy: 0.8421\n",
            "Epoch 828/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2829 - accuracy: 0.8802 - val_loss: 0.4019 - val_accuracy: 0.8455\n",
            "Epoch 829/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2822 - accuracy: 0.8821 - val_loss: 0.3998 - val_accuracy: 0.8459\n",
            "Epoch 830/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2820 - accuracy: 0.8836 - val_loss: 0.4005 - val_accuracy: 0.8466\n",
            "Epoch 831/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2818 - accuracy: 0.8821 - val_loss: 0.3973 - val_accuracy: 0.8459\n",
            "Epoch 832/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2827 - accuracy: 0.8819 - val_loss: 0.3972 - val_accuracy: 0.8489\n",
            "Epoch 833/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2828 - accuracy: 0.8809 - val_loss: 0.4001 - val_accuracy: 0.8459\n",
            "Epoch 834/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2825 - accuracy: 0.8811 - val_loss: 0.4005 - val_accuracy: 0.8485\n",
            "Epoch 835/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2824 - accuracy: 0.8843 - val_loss: 0.4004 - val_accuracy: 0.8444\n",
            "Epoch 836/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2823 - accuracy: 0.8821 - val_loss: 0.4014 - val_accuracy: 0.8459\n",
            "Epoch 837/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.2829 - accuracy: 0.8819 - val_loss: 0.4020 - val_accuracy: 0.8406\n",
            "Epoch 838/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2834 - accuracy: 0.8826 - val_loss: 0.4015 - val_accuracy: 0.8429\n",
            "Epoch 839/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2822 - accuracy: 0.8828 - val_loss: 0.4008 - val_accuracy: 0.8474\n",
            "Epoch 840/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2817 - accuracy: 0.8830 - val_loss: 0.4037 - val_accuracy: 0.8413\n",
            "Epoch 841/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2841 - accuracy: 0.8823 - val_loss: 0.3980 - val_accuracy: 0.8436\n",
            "Epoch 842/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2813 - accuracy: 0.8819 - val_loss: 0.4086 - val_accuracy: 0.8429\n",
            "Epoch 843/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2816 - accuracy: 0.8830 - val_loss: 0.3959 - val_accuracy: 0.8485\n",
            "Epoch 844/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2832 - accuracy: 0.8839 - val_loss: 0.3983 - val_accuracy: 0.8448\n",
            "Epoch 845/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2833 - accuracy: 0.8815 - val_loss: 0.4029 - val_accuracy: 0.8451\n",
            "Epoch 846/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2822 - accuracy: 0.8819 - val_loss: 0.4005 - val_accuracy: 0.8482\n",
            "Epoch 847/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2827 - accuracy: 0.8834 - val_loss: 0.4023 - val_accuracy: 0.8451\n",
            "Epoch 848/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2816 - accuracy: 0.8821 - val_loss: 0.3990 - val_accuracy: 0.8493\n",
            "Epoch 849/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2812 - accuracy: 0.8819 - val_loss: 0.3993 - val_accuracy: 0.8482\n",
            "Epoch 850/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2816 - accuracy: 0.8815 - val_loss: 0.4048 - val_accuracy: 0.8391\n",
            "Epoch 851/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2819 - accuracy: 0.8811 - val_loss: 0.3975 - val_accuracy: 0.8410\n",
            "Epoch 852/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2818 - accuracy: 0.8830 - val_loss: 0.4109 - val_accuracy: 0.8478\n",
            "Epoch 853/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2815 - accuracy: 0.8830 - val_loss: 0.4131 - val_accuracy: 0.8516\n",
            "Epoch 854/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2830 - accuracy: 0.8841 - val_loss: 0.3952 - val_accuracy: 0.8478\n",
            "Epoch 855/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2838 - accuracy: 0.8817 - val_loss: 0.3959 - val_accuracy: 0.8466\n",
            "Epoch 856/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2817 - accuracy: 0.8837 - val_loss: 0.4031 - val_accuracy: 0.8432\n",
            "Epoch 857/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.2828 - accuracy: 0.8795 - val_loss: 0.3987 - val_accuracy: 0.8429\n",
            "Epoch 858/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.2825 - accuracy: 0.8832 - val_loss: 0.4056 - val_accuracy: 0.8364\n",
            "Epoch 859/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2822 - accuracy: 0.8847 - val_loss: 0.4005 - val_accuracy: 0.8436\n",
            "Epoch 860/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2827 - accuracy: 0.8815 - val_loss: 0.4060 - val_accuracy: 0.8455\n",
            "Epoch 861/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2843 - accuracy: 0.8815 - val_loss: 0.3952 - val_accuracy: 0.8451\n",
            "Epoch 862/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2832 - accuracy: 0.8815 - val_loss: 0.4001 - val_accuracy: 0.8417\n",
            "Epoch 863/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2827 - accuracy: 0.8845 - val_loss: 0.4156 - val_accuracy: 0.8353\n",
            "Epoch 864/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2809 - accuracy: 0.8864 - val_loss: 0.4008 - val_accuracy: 0.8455\n",
            "Epoch 865/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2810 - accuracy: 0.8830 - val_loss: 0.4032 - val_accuracy: 0.8372\n",
            "Epoch 866/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2831 - accuracy: 0.8828 - val_loss: 0.4089 - val_accuracy: 0.8413\n",
            "Epoch 867/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2830 - accuracy: 0.8819 - val_loss: 0.3989 - val_accuracy: 0.8429\n",
            "Epoch 868/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2835 - accuracy: 0.8837 - val_loss: 0.3988 - val_accuracy: 0.8448\n",
            "Epoch 869/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2821 - accuracy: 0.8856 - val_loss: 0.3995 - val_accuracy: 0.8440\n",
            "Epoch 870/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2823 - accuracy: 0.8834 - val_loss: 0.4023 - val_accuracy: 0.8429\n",
            "Epoch 871/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2823 - accuracy: 0.8837 - val_loss: 0.3997 - val_accuracy: 0.8485\n",
            "Epoch 872/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2826 - accuracy: 0.8813 - val_loss: 0.4001 - val_accuracy: 0.8425\n",
            "Epoch 873/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2829 - accuracy: 0.8804 - val_loss: 0.4063 - val_accuracy: 0.8338\n",
            "Epoch 874/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2815 - accuracy: 0.8824 - val_loss: 0.3990 - val_accuracy: 0.8451\n",
            "Epoch 875/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2834 - accuracy: 0.8809 - val_loss: 0.4009 - val_accuracy: 0.8425\n",
            "Epoch 876/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2821 - accuracy: 0.8828 - val_loss: 0.3974 - val_accuracy: 0.8501\n",
            "Epoch 877/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2819 - accuracy: 0.8815 - val_loss: 0.3978 - val_accuracy: 0.8451\n",
            "Epoch 878/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2804 - accuracy: 0.8854 - val_loss: 0.4033 - val_accuracy: 0.8440\n",
            "Epoch 879/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2816 - accuracy: 0.8847 - val_loss: 0.3998 - val_accuracy: 0.8466\n",
            "Epoch 880/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2809 - accuracy: 0.8819 - val_loss: 0.4042 - val_accuracy: 0.8470\n",
            "Epoch 881/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2833 - accuracy: 0.8808 - val_loss: 0.4014 - val_accuracy: 0.8429\n",
            "Epoch 882/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2810 - accuracy: 0.8821 - val_loss: 0.4024 - val_accuracy: 0.8493\n",
            "Epoch 883/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2820 - accuracy: 0.8817 - val_loss: 0.3992 - val_accuracy: 0.8466\n",
            "Epoch 884/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2832 - accuracy: 0.8828 - val_loss: 0.4040 - val_accuracy: 0.8413\n",
            "Epoch 885/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2819 - accuracy: 0.8819 - val_loss: 0.4047 - val_accuracy: 0.8489\n",
            "Epoch 886/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2790 - accuracy: 0.8869 - val_loss: 0.4003 - val_accuracy: 0.8440\n",
            "Epoch 887/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2817 - accuracy: 0.8832 - val_loss: 0.4043 - val_accuracy: 0.8436\n",
            "Epoch 888/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2822 - accuracy: 0.8826 - val_loss: 0.3951 - val_accuracy: 0.8508\n",
            "Epoch 889/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2822 - accuracy: 0.8839 - val_loss: 0.4082 - val_accuracy: 0.8470\n",
            "Epoch 890/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2815 - accuracy: 0.8824 - val_loss: 0.4034 - val_accuracy: 0.8451\n",
            "Epoch 891/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2826 - accuracy: 0.8826 - val_loss: 0.4102 - val_accuracy: 0.8395\n",
            "Epoch 892/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2823 - accuracy: 0.8817 - val_loss: 0.3960 - val_accuracy: 0.8501\n",
            "Epoch 893/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2815 - accuracy: 0.8852 - val_loss: 0.4007 - val_accuracy: 0.8466\n",
            "Epoch 894/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2820 - accuracy: 0.8841 - val_loss: 0.4031 - val_accuracy: 0.8436\n",
            "Epoch 895/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2829 - accuracy: 0.8837 - val_loss: 0.4030 - val_accuracy: 0.8444\n",
            "Epoch 896/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2821 - accuracy: 0.8793 - val_loss: 0.4023 - val_accuracy: 0.8497\n",
            "Epoch 897/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2822 - accuracy: 0.8830 - val_loss: 0.4002 - val_accuracy: 0.8489\n",
            "Epoch 898/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2814 - accuracy: 0.8821 - val_loss: 0.4055 - val_accuracy: 0.8421\n",
            "Epoch 899/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2832 - accuracy: 0.8813 - val_loss: 0.4011 - val_accuracy: 0.8519\n",
            "Epoch 900/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2819 - accuracy: 0.8839 - val_loss: 0.4007 - val_accuracy: 0.8455\n",
            "Epoch 901/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.2814 - accuracy: 0.8849 - val_loss: 0.3969 - val_accuracy: 0.8463\n",
            "Epoch 902/1000\n",
            "536/536 [==============================] - 4s 7ms/step - loss: 0.2807 - accuracy: 0.8834 - val_loss: 0.4033 - val_accuracy: 0.8413\n",
            "Epoch 903/1000\n",
            "536/536 [==============================] - 4s 7ms/step - loss: 0.2822 - accuracy: 0.8813 - val_loss: 0.4005 - val_accuracy: 0.8463\n",
            "Epoch 904/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2818 - accuracy: 0.8809 - val_loss: 0.4016 - val_accuracy: 0.8501\n",
            "Epoch 905/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2816 - accuracy: 0.8819 - val_loss: 0.4038 - val_accuracy: 0.8376\n",
            "Epoch 906/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2808 - accuracy: 0.8856 - val_loss: 0.4078 - val_accuracy: 0.8485\n",
            "Epoch 907/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2821 - accuracy: 0.8830 - val_loss: 0.4056 - val_accuracy: 0.8410\n",
            "Epoch 908/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2817 - accuracy: 0.8813 - val_loss: 0.4129 - val_accuracy: 0.8406\n",
            "Epoch 909/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2823 - accuracy: 0.8819 - val_loss: 0.4010 - val_accuracy: 0.8421\n",
            "Epoch 910/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.2826 - accuracy: 0.8828 - val_loss: 0.4086 - val_accuracy: 0.8349\n",
            "Epoch 911/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2816 - accuracy: 0.8806 - val_loss: 0.4013 - val_accuracy: 0.8436\n",
            "Epoch 912/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2811 - accuracy: 0.8834 - val_loss: 0.4092 - val_accuracy: 0.8459\n",
            "Epoch 913/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2831 - accuracy: 0.8787 - val_loss: 0.4039 - val_accuracy: 0.8463\n",
            "Epoch 914/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2835 - accuracy: 0.8843 - val_loss: 0.4011 - val_accuracy: 0.8413\n",
            "Epoch 915/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2825 - accuracy: 0.8796 - val_loss: 0.3998 - val_accuracy: 0.8463\n",
            "Epoch 916/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.2817 - accuracy: 0.8823 - val_loss: 0.4024 - val_accuracy: 0.8459\n",
            "Epoch 917/1000\n",
            "536/536 [==============================] - 3s 6ms/step - loss: 0.2833 - accuracy: 0.8824 - val_loss: 0.4041 - val_accuracy: 0.8451\n",
            "Epoch 918/1000\n",
            "536/536 [==============================] - 4s 7ms/step - loss: 0.2806 - accuracy: 0.8824 - val_loss: 0.3985 - val_accuracy: 0.8429\n",
            "Epoch 919/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2825 - accuracy: 0.8834 - val_loss: 0.3999 - val_accuracy: 0.8459\n",
            "Epoch 920/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2832 - accuracy: 0.8819 - val_loss: 0.4074 - val_accuracy: 0.8429\n",
            "Epoch 921/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2837 - accuracy: 0.8796 - val_loss: 0.3992 - val_accuracy: 0.8466\n",
            "Epoch 922/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2822 - accuracy: 0.8856 - val_loss: 0.4039 - val_accuracy: 0.8429\n",
            "Epoch 923/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2802 - accuracy: 0.8854 - val_loss: 0.4065 - val_accuracy: 0.8470\n",
            "Epoch 924/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2830 - accuracy: 0.8809 - val_loss: 0.3963 - val_accuracy: 0.8455\n",
            "Epoch 925/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2826 - accuracy: 0.8819 - val_loss: 0.3980 - val_accuracy: 0.8474\n",
            "Epoch 926/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.2822 - accuracy: 0.8813 - val_loss: 0.3980 - val_accuracy: 0.8413\n",
            "Epoch 927/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2807 - accuracy: 0.8819 - val_loss: 0.3967 - val_accuracy: 0.8444\n",
            "Epoch 928/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.2811 - accuracy: 0.8836 - val_loss: 0.4090 - val_accuracy: 0.8455\n",
            "Epoch 929/1000\n",
            "536/536 [==============================] - 3s 6ms/step - loss: 0.2821 - accuracy: 0.8824 - val_loss: 0.4054 - val_accuracy: 0.8410\n",
            "Epoch 930/1000\n",
            "536/536 [==============================] - 3s 6ms/step - loss: 0.2830 - accuracy: 0.8826 - val_loss: 0.3986 - val_accuracy: 0.8432\n",
            "Epoch 931/1000\n",
            "536/536 [==============================] - 3s 6ms/step - loss: 0.2806 - accuracy: 0.8826 - val_loss: 0.4125 - val_accuracy: 0.8360\n",
            "Epoch 932/1000\n",
            "536/536 [==============================] - 3s 6ms/step - loss: 0.2839 - accuracy: 0.8836 - val_loss: 0.4007 - val_accuracy: 0.8436\n",
            "Epoch 933/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.2807 - accuracy: 0.8836 - val_loss: 0.4075 - val_accuracy: 0.8379\n",
            "Epoch 934/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2820 - accuracy: 0.8847 - val_loss: 0.4018 - val_accuracy: 0.8482\n",
            "Epoch 935/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2812 - accuracy: 0.8832 - val_loss: 0.4036 - val_accuracy: 0.8478\n",
            "Epoch 936/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2821 - accuracy: 0.8823 - val_loss: 0.3999 - val_accuracy: 0.8451\n",
            "Epoch 937/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2812 - accuracy: 0.8823 - val_loss: 0.4017 - val_accuracy: 0.8485\n",
            "Epoch 938/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.2813 - accuracy: 0.8836 - val_loss: 0.4071 - val_accuracy: 0.8383\n",
            "Epoch 939/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2813 - accuracy: 0.8836 - val_loss: 0.4028 - val_accuracy: 0.8455\n",
            "Epoch 940/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2797 - accuracy: 0.8817 - val_loss: 0.3986 - val_accuracy: 0.8455\n",
            "Epoch 941/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2812 - accuracy: 0.8826 - val_loss: 0.3999 - val_accuracy: 0.8482\n",
            "Epoch 942/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2806 - accuracy: 0.8815 - val_loss: 0.4059 - val_accuracy: 0.8501\n",
            "Epoch 943/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2815 - accuracy: 0.8830 - val_loss: 0.3980 - val_accuracy: 0.8448\n",
            "Epoch 944/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2813 - accuracy: 0.8811 - val_loss: 0.4015 - val_accuracy: 0.8455\n",
            "Epoch 945/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2818 - accuracy: 0.8824 - val_loss: 0.4020 - val_accuracy: 0.8425\n",
            "Epoch 946/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.2820 - accuracy: 0.8802 - val_loss: 0.4027 - val_accuracy: 0.8429\n",
            "Epoch 947/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2809 - accuracy: 0.8843 - val_loss: 0.3987 - val_accuracy: 0.8463\n",
            "Epoch 948/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2805 - accuracy: 0.8832 - val_loss: 0.4061 - val_accuracy: 0.8406\n",
            "Epoch 949/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.2822 - accuracy: 0.8830 - val_loss: 0.3984 - val_accuracy: 0.8497\n",
            "Epoch 950/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2833 - accuracy: 0.8824 - val_loss: 0.4032 - val_accuracy: 0.8474\n",
            "Epoch 951/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2814 - accuracy: 0.8837 - val_loss: 0.4036 - val_accuracy: 0.8470\n",
            "Epoch 952/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.2814 - accuracy: 0.8793 - val_loss: 0.3995 - val_accuracy: 0.8482\n",
            "Epoch 953/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2817 - accuracy: 0.8806 - val_loss: 0.3983 - val_accuracy: 0.8485\n",
            "Epoch 954/1000\n",
            "536/536 [==============================] - 4s 7ms/step - loss: 0.2811 - accuracy: 0.8845 - val_loss: 0.3968 - val_accuracy: 0.8493\n",
            "Epoch 955/1000\n",
            "536/536 [==============================] - 4s 7ms/step - loss: 0.2805 - accuracy: 0.8841 - val_loss: 0.4009 - val_accuracy: 0.8478\n",
            "Epoch 956/1000\n",
            "536/536 [==============================] - 4s 8ms/step - loss: 0.2814 - accuracy: 0.8836 - val_loss: 0.4007 - val_accuracy: 0.8459\n",
            "Epoch 957/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.2822 - accuracy: 0.8824 - val_loss: 0.4021 - val_accuracy: 0.8482\n",
            "Epoch 958/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2812 - accuracy: 0.8841 - val_loss: 0.3957 - val_accuracy: 0.8459\n",
            "Epoch 959/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.2802 - accuracy: 0.8834 - val_loss: 0.4080 - val_accuracy: 0.8519\n",
            "Epoch 960/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2822 - accuracy: 0.8821 - val_loss: 0.3953 - val_accuracy: 0.8455\n",
            "Epoch 961/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.2818 - accuracy: 0.8834 - val_loss: 0.4001 - val_accuracy: 0.8455\n",
            "Epoch 962/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2823 - accuracy: 0.8836 - val_loss: 0.3999 - val_accuracy: 0.8482\n",
            "Epoch 963/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2807 - accuracy: 0.8815 - val_loss: 0.4036 - val_accuracy: 0.8463\n",
            "Epoch 964/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2817 - accuracy: 0.8824 - val_loss: 0.4079 - val_accuracy: 0.8387\n",
            "Epoch 965/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2803 - accuracy: 0.8843 - val_loss: 0.4006 - val_accuracy: 0.8451\n",
            "Epoch 966/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2804 - accuracy: 0.8852 - val_loss: 0.4066 - val_accuracy: 0.8360\n",
            "Epoch 967/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2821 - accuracy: 0.8815 - val_loss: 0.4145 - val_accuracy: 0.8353\n",
            "Epoch 968/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2830 - accuracy: 0.8793 - val_loss: 0.3984 - val_accuracy: 0.8436\n",
            "Epoch 969/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.2814 - accuracy: 0.8837 - val_loss: 0.3975 - val_accuracy: 0.8466\n",
            "Epoch 970/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2802 - accuracy: 0.8871 - val_loss: 0.4019 - val_accuracy: 0.8448\n",
            "Epoch 971/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2806 - accuracy: 0.8851 - val_loss: 0.4033 - val_accuracy: 0.8448\n",
            "Epoch 972/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.2804 - accuracy: 0.8821 - val_loss: 0.4026 - val_accuracy: 0.8466\n",
            "Epoch 973/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2813 - accuracy: 0.8836 - val_loss: 0.4053 - val_accuracy: 0.8413\n",
            "Epoch 974/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2813 - accuracy: 0.8811 - val_loss: 0.4004 - val_accuracy: 0.8474\n",
            "Epoch 975/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2833 - accuracy: 0.8796 - val_loss: 0.3982 - val_accuracy: 0.8474\n",
            "Epoch 976/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2805 - accuracy: 0.8852 - val_loss: 0.4015 - val_accuracy: 0.8432\n",
            "Epoch 977/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2821 - accuracy: 0.8830 - val_loss: 0.4024 - val_accuracy: 0.8440\n",
            "Epoch 978/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2817 - accuracy: 0.8823 - val_loss: 0.4012 - val_accuracy: 0.8398\n",
            "Epoch 979/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2804 - accuracy: 0.8828 - val_loss: 0.3988 - val_accuracy: 0.8413\n",
            "Epoch 980/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2829 - accuracy: 0.8796 - val_loss: 0.3979 - val_accuracy: 0.8489\n",
            "Epoch 981/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2835 - accuracy: 0.8798 - val_loss: 0.4003 - val_accuracy: 0.8508\n",
            "Epoch 982/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2817 - accuracy: 0.8813 - val_loss: 0.3983 - val_accuracy: 0.8493\n",
            "Epoch 983/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2825 - accuracy: 0.8841 - val_loss: 0.3993 - val_accuracy: 0.8455\n",
            "Epoch 984/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2825 - accuracy: 0.8824 - val_loss: 0.4002 - val_accuracy: 0.8459\n",
            "Epoch 985/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2817 - accuracy: 0.8793 - val_loss: 0.4045 - val_accuracy: 0.8429\n",
            "Epoch 986/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2805 - accuracy: 0.8843 - val_loss: 0.4096 - val_accuracy: 0.8440\n",
            "Epoch 987/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2821 - accuracy: 0.8800 - val_loss: 0.4070 - val_accuracy: 0.8372\n",
            "Epoch 988/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2817 - accuracy: 0.8828 - val_loss: 0.4062 - val_accuracy: 0.8448\n",
            "Epoch 989/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2818 - accuracy: 0.8806 - val_loss: 0.4042 - val_accuracy: 0.8440\n",
            "Epoch 990/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2817 - accuracy: 0.8808 - val_loss: 0.3985 - val_accuracy: 0.8482\n",
            "Epoch 991/1000\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.2831 - accuracy: 0.8815 - val_loss: 0.3960 - val_accuracy: 0.8493\n",
            "Epoch 992/1000\n",
            "536/536 [==============================] - 3s 6ms/step - loss: 0.2830 - accuracy: 0.8821 - val_loss: 0.4023 - val_accuracy: 0.8444\n",
            "Epoch 993/1000\n",
            "536/536 [==============================] - 4s 7ms/step - loss: 0.2830 - accuracy: 0.8798 - val_loss: 0.4033 - val_accuracy: 0.8485\n",
            "Epoch 994/1000\n",
            "536/536 [==============================] - 3s 6ms/step - loss: 0.2806 - accuracy: 0.8811 - val_loss: 0.3973 - val_accuracy: 0.8455\n",
            "Epoch 995/1000\n",
            "536/536 [==============================] - 3s 6ms/step - loss: 0.2812 - accuracy: 0.8856 - val_loss: 0.4005 - val_accuracy: 0.8448\n",
            "Epoch 996/1000\n",
            "536/536 [==============================] - 4s 7ms/step - loss: 0.2814 - accuracy: 0.8800 - val_loss: 0.4022 - val_accuracy: 0.8429\n",
            "Epoch 997/1000\n",
            "536/536 [==============================] - 4s 7ms/step - loss: 0.2814 - accuracy: 0.8841 - val_loss: 0.3989 - val_accuracy: 0.8455\n",
            "Epoch 998/1000\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.2818 - accuracy: 0.8815 - val_loss: 0.4002 - val_accuracy: 0.8398\n",
            "Epoch 999/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.2834 - accuracy: 0.8802 - val_loss: 0.4037 - val_accuracy: 0.8474\n",
            "Epoch 1000/1000\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.2808 - accuracy: 0.8832 - val_loss: 0.4031 - val_accuracy: 0.8451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### at one point of time the accuracy will become almost same\n",
        "##so where to stop ???"
      ],
      "metadata": {
        "id": "nSz9ZT4sMqRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# how many no. of epochs to decide. "
      ],
      "metadata": {
        "id": "49LrH270MIiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# early stopping - when the accuracy is not increasing , the training vl stop automatically."
      ],
      "metadata": {
        "id": "ROX8F0wcM2qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# early stopping - we will have to add that code\n",
        "\n",
        "#model_history will give all the parameters"
      ],
      "metadata": {
        "id": "4c7Me17LM2zh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#list all data in history\n",
        "model_history.history.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3lkwxT8MfTD",
        "outputId": "35e74267-0f92-458d-b6eb-a1ed1a88c417"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(model_history.history['accuracy'])\n",
        "plt.plot(model_history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Kz6skGJ1Mfff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "ad926cac-05a3-4818-f167-32b89efa03a6"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for loss\n",
        "plt.plot(model_history.history['loss'])\n",
        "plt.plot(model_history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "fLkJhQH26okT",
        "outputId": "1cd1eaf2-9927-435b-9265-28dc982885a7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 3 - Making the predictions and evaluating the model\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sl6GQG06ufL",
        "outputId": "d2690227-83f0-4357-f2c5-26ba96120140"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ChOmWG-6yKq",
        "outputId": "bd045b5e-f861-49bb-a5c7-df7a3ea85bd3"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1471,  124],\n",
              "       [ 198,  207]])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the Accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "score=accuracy_score(y_pred,y_test)"
      ],
      "metadata": {
        "id": "dEikOMYN61d2"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acBxry6I63yA",
        "outputId": "0d5be7bd-6568-4f77-da7a-38210848add0"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.839"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# yaye :)"
      ],
      "metadata": {
        "id": "ShxJJusC64_v"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the weights\n",
        "classifier.get_weights()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAFb72VH67U6",
        "outputId": "5f32518c-4249-4a85-8bb9-205121134a86"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-5.85192926e-02,  7.85414502e-03,  2.05926120e-01,\n",
              "         -1.57477334e-01, -4.17938322e-01,  4.24100906e-01,\n",
              "          1.40196569e-02, -1.94820598e-01, -4.39715415e-01,\n",
              "          3.38146299e-01, -4.88933641e-03],\n",
              "        [ 3.56664628e-01, -3.35925847e-01,  2.20992041e+00,\n",
              "          5.99291325e-01,  4.09748763e-01, -3.21540743e-01,\n",
              "          2.97852248e-01, -1.00041854e+00,  1.57663262e+00,\n",
              "          1.30797625e+00, -9.42528427e-01],\n",
              "        [ 4.14961996e-03,  2.34612718e-01, -9.50845838e-01,\n",
              "          1.20042875e-01,  4.24543768e-02,  5.23655534e-01,\n",
              "          1.39577538e-02, -4.16918360e-02, -5.70032537e-01,\n",
              "          1.67871118e+00, -9.12177414e-02],\n",
              "        [-4.34217155e-01, -1.20081377e+00, -1.26191497e+00,\n",
              "         -1.40556309e-04,  4.36717212e-01, -1.66372728e+00,\n",
              "         -1.65758109e+00, -1.09937474e-01, -9.90984082e-01,\n",
              "          3.18877965e-01,  9.65401158e-02],\n",
              "        [ 1.89414263e+00, -4.32657272e-01, -8.43008161e-02,\n",
              "         -1.28550124e+00, -5.48447430e-01, -5.90880394e-01,\n",
              "         -2.24188662e+00, -1.73125291e+00, -4.86673951e-01,\n",
              "         -3.89880270e-01,  2.59173840e-01],\n",
              "        [-3.16485837e-02, -9.50647965e-02,  2.27265107e-03,\n",
              "         -2.08361045e-01, -4.73390490e-01, -7.76410475e-02,\n",
              "         -1.42991140e-01,  6.54189646e-01, -2.64867216e-01,\n",
              "         -5.42663643e-03,  3.28220993e-01],\n",
              "        [-6.30980134e-01,  6.64847903e-03,  1.26791191e+00,\n",
              "         -1.22474539e+00,  3.68846387e-01, -1.56507954e-01,\n",
              "          1.58327803e-01,  3.89074206e-01,  1.25871611e+00,\n",
              "          1.22753251e+00, -6.00874960e-01],\n",
              "        [ 1.03134297e-01, -3.16817433e-01, -6.43368185e-01,\n",
              "         -4.24431637e-02,  6.75691843e-01,  1.33373213e+00,\n",
              "          3.09710354e-02,  4.08416122e-01,  3.16991717e-01,\n",
              "         -2.36918911e-01, -7.76850507e-02],\n",
              "        [ 1.18918903e-03, -6.28602087e-01,  1.47285357e-01,\n",
              "         -1.36637777e-01,  1.59428656e-01, -5.51029146e-01,\n",
              "          7.05822289e-01, -1.64922282e-01, -2.51859158e-01,\n",
              "          4.70705390e-01,  2.36491263e-01],\n",
              "        [ 2.32807040e-01,  5.02757192e-01, -1.21342659e-01,\n",
              "          3.00306469e-01, -8.13383818e-01,  6.05347395e-01,\n",
              "          1.88775867e-01, -7.86708474e-01, -5.87081946e-02,\n",
              "         -1.68330342e-01, -1.96050501e+00],\n",
              "        [ 4.13773321e-02,  2.31861129e-01,  4.09431197e-02,\n",
              "          8.22448507e-02, -5.16846240e-01,  1.10224080e+00,\n",
              "         -8.47964883e-02,  1.15380876e-01, -4.63520646e-01,\n",
              "          8.00056159e-01,  5.34041107e-01]], dtype=float32),\n",
              " array([-0.24931964,  1.689148  , -1.5237867 , -0.06827471,  0.8680679 ,\n",
              "         0.40767482, -0.41653785, -0.21163398,  0.6575956 , -0.9607186 ,\n",
              "         0.8714979 ], dtype=float32),\n",
              " array([[-0.6375661 , -0.7493624 ,  1.0445212 , -0.51835763, -0.2823254 ,\n",
              "         -0.13793436, -0.34713224],\n",
              "        [ 0.54357654, -0.42227763, -0.298668  ,  0.686856  ,  0.5704261 ,\n",
              "         -0.80040264,  0.22388628],\n",
              "        [-0.13875382,  0.29968607, -1.0168073 , -0.2304053 , -0.69457126,\n",
              "         -3.050733  ,  0.38953984],\n",
              "        [-0.6819898 , -0.035381  ,  0.49731755, -0.200607  , -0.47284648,\n",
              "         -0.10774637, -0.33723354],\n",
              "        [ 0.17822279, -0.63289744,  0.82482517,  0.16050917,  0.7141955 ,\n",
              "          0.49576527,  0.9917072 ],\n",
              "        [ 0.12179916,  0.2627455 ,  2.4502256 ,  0.47824886, -0.0753595 ,\n",
              "         -0.01097163,  1.3608428 ],\n",
              "        [-0.6987932 , -0.6155867 , -0.7293942 , -1.2631844 ,  1.1285335 ,\n",
              "          0.8127148 ,  0.70017326],\n",
              "        [-1.5173097 ,  0.63787395,  1.3900324 , -0.09408231,  0.37145913,\n",
              "         -0.36919093,  0.12791951],\n",
              "        [ 0.21087433,  0.9625252 , -0.22836833, -0.27199805, -0.95411557,\n",
              "          1.0022643 , -1.0751241 ],\n",
              "        [-0.29252005,  0.7009597 ,  0.6107524 , -0.41685814, -0.85798424,\n",
              "         -2.3111088 , -1.0422186 ],\n",
              "        [ 0.7116932 ,  0.71266073, -0.7611066 ,  0.06346258, -0.29607612,\n",
              "          0.8718289 , -0.39624628]], dtype=float32),\n",
              " array([ 1.6788398 ,  0.63139355, -1.3587143 ,  1.7414724 ,  1.4538679 ,\n",
              "        -0.13640113,  0.2579445 ], dtype=float32),\n",
              " array([[-0.7532854 , -0.82708   ,  0.63598055, -0.12402176, -0.30254987,\n",
              "          0.3825617 ],\n",
              "        [-0.09888306, -0.14520046, -0.27552423,  0.47421166, -0.3802095 ,\n",
              "          0.28307837],\n",
              "        [ 0.11885677,  1.6719702 , -0.16058615,  1.3432021 , -0.16106176,\n",
              "          0.3532554 ],\n",
              "        [-0.92456114, -0.8036086 ,  0.57887053,  0.11897178, -0.3660992 ,\n",
              "         -0.23497647],\n",
              "        [-1.1251625 ,  0.21546184,  0.9469321 ,  0.43990976, -0.42492378,\n",
              "         -0.05815883],\n",
              "        [ 0.82524174, -0.45847175,  0.4146767 ,  0.4142039 ,  0.05307636,\n",
              "         -7.5259867 ],\n",
              "        [ 0.25763428,  0.32018408, -2.3372667 ,  0.4779269 , -0.5043457 ,\n",
              "         -0.21175732]], dtype=float32),\n",
              " array([ 2.0101225 , -0.26047403, -0.15057024, -1.4712453 , -0.03140154,\n",
              "         1.0131198 ], dtype=float32),\n",
              " array([[ 1.4599491 ],\n",
              "        [ 1.0656961 ],\n",
              "        [-0.88251644],\n",
              "        [-1.0312047 ],\n",
              "        [-0.8196394 ],\n",
              "        [-1.0595727 ]], dtype=float32),\n",
              " array([1.8475041], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1Emn7HNK7o0V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}